# 2.3 性能优化特性（Rust 1.90）

## 📋 目录

- [2.3 性能优化特性（Rust 1.90）](#23-性能优化特性rust-190)
  - [📋 目录](#-目录)
  - [2.3.1 编译与产物](#231-编译与产物)
  - [2.3.2 内存与数据模型](#232-内存与数据模型)
  - [2.3.3 并发与调度](#233-并发与调度)
  - [2.3.4 网络 IO](#234-网络-io)
  - [2.3.5 序列化/反序列化](#235-序列化反序列化)
  - [2.3.6 基准与剖析](#236-基准与剖析)
  - [2.3.7 与本仓示例的结合](#237-与本仓示例的结合)
  - [2.3.8 与蓝图的性能对齐](#238-与蓝图的性能对齐)
  - [2.3.9 网络与 hyper 调优（片段）](#239-网络与-hyper-调优片段)
  - [2.3.10 JSON 性能：serde\_json vs simd-json（片段）](#2310-json-性能serde_json-vs-simd-json片段)
  - [2.3.11 微基准：criterion 模板](#2311-微基准criterion-模板)
  - [2.3.12 异步可观测：tokio-console](#2312-异步可观测tokio-console)
  - [2.3.13 生产剖析：pprof 火焰图](#2313-生产剖析pprof-火焰图)
  - [2.3.14 压测模板：wrk/hey/k6/ghz](#2314-压测模板wrkheyk6ghz)

本章从编译产物、内存布局、并发调度、网络 IO、序列化/反序列化、基准测试六个维度梳理 Rust 1.90 生态在微服务的性能策略。

## 2.3.1 编译与产物

- LTO/ThinLTO、`codegen-units=1`、`opt-level=z/s`（函数体小/冷路径）与 `opt-level=3`（热路径二进制）分情景配置。
- `panic = 'abort'` 适用于 sidecar/工具型进程；服务主进程保持 `unwind` 便于错误边界。

示例 `Cargo.toml` 片段：

```toml
[profile.release]
codegen-units = 1
lto = "thin"
opt-level = 3
panic = "unwind"
strip = true
```

## 2.3.2 内存与数据模型

- 使用 `SmallVec`, `bytes::Bytes`, `ahash` 优化小容器与哈希表热点。
- 避免不必要的 `clone`；利用 `Cow`、`Arc<str>` 降低拷贝成本。
- 紧凑结构体布局，关注对齐与填充；为热路径字段靠前布局（cache locality）。

## 2.3.3 并发与调度

- 区分 CPU 密集（`spawn_blocking` 或 rayon）与 IO 密集（Tokio）任务池。
- 背压：限流中间件（并发数、令牌桶）、超时、队列长度与丢弃策略。
- 零拷贝：`hyper`/`axum` 结合 `Bytes` 与 `http-body` 特性。

## 2.3.4 网络 IO

- HTTP/1.1 与 HTTP/2 复用；gRPC（HTTP/2）在流式与低延迟场景更优。
- 连接池：重用与上限；DNS 解析缓存；TLS 会话复用。
- Keep-Alive、`tcp_nodelay`、拥塞控制参数按环境调优。

## 2.3.5 序列化/反序列化

- `serde_json`（通用）、`simd-json`（x86 SIMD 加速）、`rmp-serde`（二进制）、`bincode`（内部 RPC）。
- 定义稳定的 API 模型；对外保守，对内可用更致密格式。

## 2.3.6 基准与剖析

- 使用 `criterion` 微基准；`tokio-console` 观测异步任务；`pprof` 火焰图。
- 标准化端到端压测（wrk/hey/ghz/k6）并纳入 CI 阈值。

## 2.3.7 与本仓示例的结合

- 结合 `ServiceMonitor` 统一记录成功率与 P50/P95/P99 延迟（可扩展直方图）。
- 将负载均衡策略参数化，通过配置中心热更新。
- 在 retry/circuitbreaker 的热路径上避免动态分配，重用缓冲区。

## 2.3.8 与蓝图的性能对齐

- 14.1：HTTP 层零拷贝、连接池、simd-json 选择；N+1 查询消除。
- 14.2：gRPC/HTTP2 多路复用与连接复用；DNS 缓存与 keepalive。
- 14.3：Kafka 批次/压缩；消费者并发与再均衡监控；pprof 火焰图。
- 14.4：Actix/axum 的 Bytes + 批处理；网络参数与限流策略联动。
- 14.5/14.6：Mesh 下减少重复重试；跨区域延迟预算与超时分解。

## 2.3.9 网络与 hyper 调优（片段）

```rust
use axum::{Router, routing::get};
use hyper::server::conn::http1;
use hyper_util::rt::TokioIo;
use tokio::net::TcpListener;
use std::time::Duration;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let app = Router::new().route("/health", get(|| async { "OK" }));

    let listener = TcpListener::bind("0.0.0.0:3000").await?;
    loop {
        let (stream, _) = listener.accept().await?;
        stream.set_nodelay(true)?; // tcp_nodelay
        stream.set_keepalive(Some(Duration::from_secs(60)))?; // keepalive
        let io = TokioIo::new(stream);
        let svc = app.clone().into_make_service_with_connect_info::<std::net::SocketAddr>();
        tokio::spawn(async move {
            if let Err(err) = http1::Builder::new().preserve_header_case(true).serve_connection(io, svc).await {
                eprintln!("server error: {err}");
            }
        });
    }
}
```

- 要点：`set_nodelay/keepalive`、连接上限、HTTP/2 时关注多路复用与窗口大小。

## 2.3.10 JSON 性能：serde_json vs simd-json（片段）

```toml
# Cargo.toml
[dependencies]
serde = { version = "1", features = ["derive"] }
serde_json = "1"
simd-json = { version = "0.13", features = ["serde_impl"] }
```

```rust
#[cfg(all(target_arch = "x86_64", feature = "simd"))]
use simd_json as json;
#[cfg(not(all(target_arch = "x86_64", feature = "simd")))]
use serde_json as json;

#[derive(serde::Deserialize, serde::Serialize)]
struct Payload { id: u64, name: String, data: Vec<u8> }

fn parse(buf: &mut [u8]) -> anyhow::Result<Payload> {
    // simd-json 需要可变切片，以就地解析
    Ok(json::from_slice(buf)?)
}
```

- 建议：对外 API 用 serde_json 保守；内部热路径可选择 simd-json（受目标平台限制）。

## 2.3.11 微基准：criterion 模板

```toml
# Cargo.toml
[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports"] }

[[bench]]
name = "comprehensive_benchmark"
harness = false
```

```rust
// benches/comprehensive_benchmark.rs
use criterion::{criterion_group, criterion_main, Criterion, black_box};

fn bench_json(c: &mut Criterion) {
    c.bench_function("serde_json_parse", |b| {
        let input = br#"{\"id\":1,\"name\":\"a\",\"data\":[1,2,3]}"#.to_vec();
        b.iter(|| {
            let mut buf = input.clone();
            let v: serde_json::Value = serde_json::from_slice(&buf).unwrap();
            black_box(v);
        })
    });
}

criterion_group!(benches, bench_json);
criterion_main!(benches);
```

- 输出 HTML 报告对比不同实现差异；纳入 CI 做回归监控。

## 2.3.12 异步可观测：tokio-console

```toml
# Cargo.toml（开发环境）
[dependencies]
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "registry"] }
console-subscriber = "0.2"
```

```rust
#[tokio::main]
async fn main() {
    console_subscriber::init();
    // ... app
}
```

- 在开发/压测环境观察任务排队、Waker、资源占用，定位阻塞点。

## 2.3.13 生产剖析：pprof 火焰图

```toml
[dependencies]
pprof = { version = "0.13", features = ["flamegraph", "frame-pointer"] }
```

```rust
use pprof::protos::Message;
use pprof::ProfilerGuard;

fn profile() {
    let guard = ProfilerGuard::new(100).unwrap();
    // 运行负载...
    if let Ok(report) = guard.report().build() {
        let mut file = std::fs::File::create("flame.svg").unwrap();
        report.flamegraph(&mut file).unwrap();
    }
}
```

- 注意：仅在准生产或受控环境开启；结合采样与白名单控制。

## 2.3.14 压测模板：wrk/hey/k6/ghz

```bash
# HTTP: wrk
wrk -t4 -c256 -d30s --latency http://localhost:3000/api

# HTTP: hey
hey -z 30s -c 200 -q 100 http://localhost:3000/api

# gRPC: ghz
ghz --insecure --call user.UserService/GetUser -d '{"id":1}' 0.0.0.0:50051

# k6（HTTP）
cat <<'EOF' > k6.js
import http from 'k6/http';
import { sleep } from 'k6';
export const options = { vus: 200, duration: '30s' };
export default function () { http.get('http://localhost:3000/api'); sleep(0.1); }
EOF
k6 run k6.js
```

- 在 CI 中设定 P95/P99 与错误率阈值，失败即红线。
