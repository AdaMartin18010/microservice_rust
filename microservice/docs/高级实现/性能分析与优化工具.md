# 性能分析与优化工具

## 概述

本文档提供了完整的性能分析与优化工具集，帮助开发者识别性能瓶颈、分析系统行为、优化代码性能。这些工具大大提高了系统性能优化的效率和准确性。

## 学习目标

- 掌握性能分析的基本原理和方法
- 学习使用各种性能分析工具
- 了解性能优化的策略和技巧
- 掌握性能监控和调优方法

## 1. 性能分析工具

### 1.1 CPU性能分析器

```rust
// CPU性能分析器
use std::time::{Duration, Instant};
use std::sync::atomic::{AtomicU64, Ordering};
use std::collections::HashMap;

pub struct CPUProfiler {
    samples: Arc<RwLock<HashMap<String, Vec<Duration>>>>,
    active_profiles: Arc<RwLock<HashMap<String, Instant>>>,
    sample_count: AtomicU64,
}

impl CPUProfiler {
    pub fn new() -> Self {
        Self {
            samples: Arc::new(RwLock::new(HashMap::new())),
            active_profiles: Arc::new(RwLock::new(HashMap::new())),
            sample_count: AtomicU64::new(0),
        }
    }
    
    pub fn start_profile(&self, name: &str) {
        let mut active = self.active_profiles.write().unwrap();
        active.insert(name.to_string(), Instant::now());
    }
    
    pub fn end_profile(&self, name: &str) {
        let mut active = self.active_profiles.write().unwrap();
        if let Some(start_time) = active.remove(name) {
            let duration = start_time.elapsed();
            
            let mut samples = self.samples.write().unwrap();
            samples.entry(name.to_string())
                .or_insert_with(Vec::new)
                .push(duration);
            
            self.sample_count.fetch_add(1, Ordering::Relaxed);
        }
    }
    
    pub fn get_stats(&self) -> HashMap<String, ProfileStats> {
        let samples = self.samples.read().unwrap();
        let mut stats = HashMap::new();
        
        for (name, durations) in samples.iter() {
            if !durations.is_empty() {
                let total: Duration = durations.iter().sum();
                let avg = total / durations.len() as u32;
                let min = durations.iter().min().copied().unwrap_or(Duration::ZERO);
                let max = durations.iter().max().copied().unwrap_or(Duration::ZERO);
                
                stats.insert(name.clone(), ProfileStats {
                    count: durations.len(),
                    total_time: total,
                    average_time: avg,
                    min_time: min,
                    max_time: max,
                });
            }
        }
        
        stats
    }
}

#[derive(Debug, Clone)]
pub struct ProfileStats {
    pub count: usize,
    pub total_time: Duration,
    pub average_time: Duration,
    pub min_time: Duration,
    pub max_time: Duration,
}

// 性能分析宏
#[macro_export]
macro_rules! profile {
    ($name:expr, $code:block) => {{
        let profiler = CPUProfiler::new();
        profiler.start_profile($name);
        let result = $code;
        profiler.end_profile($name);
        result
    }};
}
```

### 1.2 内存分析器

```rust
// 内存分析器
use std::alloc::{GlobalAlloc, Layout, System};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::collections::HashMap;

pub struct MemoryProfiler {
    allocations: AtomicUsize,
    deallocations: AtomicUsize,
    total_allocated: AtomicUsize,
    peak_memory: AtomicUsize,
    allocation_sizes: Arc<RwLock<HashMap<usize, usize>>>,
}

pub struct ProfilingAllocator {
    profiler: Arc<MemoryProfiler>,
    inner: System,
}

impl MemoryProfiler {
    pub fn new() -> Self {
        Self {
            allocations: AtomicUsize::new(0),
            deallocations: AtomicUsize::new(0),
            total_allocated: AtomicUsize::new(0),
            peak_memory: AtomicUsize::new(0),
            allocation_sizes: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    pub fn record_allocation(&self, size: usize) {
        self.allocations.fetch_add(1, Ordering::Relaxed);
        self.total_allocated.fetch_add(size, Ordering::Relaxed);
        
        let current = self.total_allocated.load(Ordering::Relaxed);
        let peak = self.peak_memory.load(Ordering::Relaxed);
        if current > peak {
            self.peak_memory.store(current, Ordering::Relaxed);
        }
        
        let mut sizes = self.allocation_sizes.write().unwrap();
        *sizes.entry(size).or_insert(0) += 1;
    }
    
    pub fn record_deallocation(&self, size: usize) {
        self.deallocations.fetch_add(1, Ordering::Relaxed);
        self.total_allocated.fetch_sub(size, Ordering::Relaxed);
    }
    
    pub fn get_stats(&self) -> MemoryStats {
        MemoryStats {
            allocations: self.allocations.load(Ordering::Relaxed),
            deallocations: self.deallocations.load(Ordering::Relaxed),
            total_allocated: self.total_allocated.load(Ordering::Relaxed),
            peak_memory: self.peak_memory.load(Ordering::Relaxed),
        }
    }
}

unsafe impl GlobalAlloc for ProfilingAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let ptr = self.inner.alloc(layout);
        if !ptr.is_null() {
            self.profiler.record_allocation(layout.size());
        }
        ptr
    }
    
    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        self.profiler.record_deallocation(layout.size());
        self.inner.dealloc(ptr, layout);
    }
}

#[derive(Debug)]
pub struct MemoryStats {
    pub allocations: usize,
    pub deallocations: usize,
    pub total_allocated: usize,
    pub peak_memory: usize,
}
```

## 2. 性能优化工具

### 2.1 代码优化器

```rust
// 代码优化器
use std::collections::HashMap;
use std::sync::Arc;

pub struct CodeOptimizer {
    optimizations: Vec<Box<dyn Optimization>>,
    metrics: Arc<RwLock<OptimizationMetrics>>,
}

pub trait Optimization: Send + Sync {
    fn name(&self) -> &str;
    fn apply(&self, code: &str) -> Result<String, OptimizationError>;
    fn can_apply(&self, code: &str) -> bool;
}

pub struct LoopOptimization;
pub struct MemoryOptimization;
pub struct AsyncOptimization;

impl Optimization for LoopOptimization {
    fn name(&self) -> &str {
        "loop_optimization"
    }
    
    fn apply(&self, code: &str) -> Result<String, OptimizationError> {
        // 实现循环优化逻辑
        // 例如：循环展开、向量化等
        Ok(code.to_string())
    }
    
    fn can_apply(&self, code: &str) -> bool {
        code.contains("for") || code.contains("while")
    }
}

impl Optimization for MemoryOptimization {
    fn name(&self) -> &str {
        "memory_optimization"
    }
    
    fn apply(&self, code: &str) -> Result<String, OptimizationError> {
        // 实现内存优化逻辑
        // 例如：减少内存分配、使用内存池等
        Ok(code.to_string())
    }
    
    fn can_apply(&self, code: &str) -> bool {
        code.contains("Vec::new") || code.contains("Box::new")
    }
}

impl Optimization for AsyncOptimization {
    fn name(&self) -> &str {
        "async_optimization"
    }
    
    fn apply(&self, code: &str) -> Result<String, OptimizationError> {
        // 实现异步优化逻辑
        // 例如：异步化同步操作、优化await使用等
        Ok(code.to_string())
    }
    
    fn can_apply(&self, code: &str) -> bool {
        code.contains("async") || code.contains("await")
    }
}

impl CodeOptimizer {
    pub fn new() -> Self {
        let mut optimizations: Vec<Box<dyn Optimization>> = Vec::new();
        optimizations.push(Box::new(LoopOptimization));
        optimizations.push(Box::new(MemoryOptimization));
        optimizations.push(Box::new(AsyncOptimization));
        
        Self {
            optimizations,
            metrics: Arc::new(RwLock::new(OptimizationMetrics::default())),
        }
    }
    
    pub fn optimize(&self, code: &str) -> Result<String, OptimizationError> {
        let mut optimized_code = code.to_string();
        let mut applied_optimizations = Vec::new();
        
        for optimization in &self.optimizations {
            if optimization.can_apply(&optimized_code) {
                match optimization.apply(&optimized_code) {
                    Ok(new_code) => {
                        optimized_code = new_code;
                        applied_optimizations.push(optimization.name().to_string());
                    }
                    Err(e) => {
                        eprintln!("Optimization {} failed: {}", optimization.name(), e);
                    }
                }
            }
        }
        
        // 更新指标
        {
            let mut metrics = self.metrics.write().unwrap();
            metrics.total_optimizations += 1;
            metrics.applied_optimizations.extend(applied_optimizations);
        }
        
        Ok(optimized_code)
    }
    
    pub fn get_metrics(&self) -> OptimizationMetrics {
        self.metrics.read().unwrap().clone()
    }
}

#[derive(Debug, Default, Clone)]
pub struct OptimizationMetrics {
    pub total_optimizations: u64,
    pub applied_optimizations: Vec<String>,
}
```

### 2.2 性能基准测试工具

```rust
// 性能基准测试工具
use std::time::{Duration, Instant};
use std::collections::HashMap;

pub struct BenchmarkRunner {
    benchmarks: HashMap<String, Box<dyn Benchmark>>,
    results: Arc<RwLock<HashMap<String, BenchmarkResult>>>,
}

pub trait Benchmark: Send + Sync {
    fn name(&self) -> &str;
    fn setup(&mut self) -> Result<(), BenchmarkError>;
    fn run(&mut self) -> Result<Duration, BenchmarkError>;
    fn teardown(&mut self) -> Result<(), BenchmarkError>;
}

pub struct FunctionBenchmark<F> {
    name: String,
    function: F,
    iterations: usize,
}

impl<F> FunctionBenchmark<F>
where
    F: Fn() -> Result<(), BenchmarkError> + Send + Sync,
{
    pub fn new(name: String, function: F, iterations: usize) -> Self {
        Self {
            name,
            function,
            iterations,
        }
    }
}

impl<F> Benchmark for FunctionBenchmark<F>
where
    F: Fn() -> Result<(), BenchmarkError> + Send + Sync,
{
    fn name(&self) -> &str {
        &self.name
    }
    
    fn setup(&mut self) -> Result<(), BenchmarkError> {
        Ok(())
    }
    
    fn run(&mut self) -> Result<Duration, BenchmarkError> {
        let start = Instant::now();
        
        for _ in 0..self.iterations {
            (self.function)()?;
        }
        
        Ok(start.elapsed())
    }
    
    fn teardown(&mut self) -> Result<(), BenchmarkError> {
        Ok(())
    }
}

impl BenchmarkRunner {
    pub fn new() -> Self {
        Self {
            benchmarks: HashMap::new(),
            results: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    pub fn add_benchmark(&mut self, benchmark: Box<dyn Benchmark>) {
        self.benchmarks.insert(benchmark.name().to_string(), benchmark);
    }
    
    pub async fn run_all(&self) -> Result<(), BenchmarkError> {
        for (name, mut benchmark) in self.benchmarks.iter_mut() {
            println!("Running benchmark: {}", name);
            
            // 设置
            benchmark.setup()?;
            
            // 运行
            let duration = benchmark.run()?;
            
            // 清理
            benchmark.teardown()?;
            
            // 记录结果
            let result = BenchmarkResult {
                name: name.clone(),
                duration,
                timestamp: chrono::Utc::now(),
            };
            
            let mut results = self.results.write().unwrap();
            results.insert(name.clone(), result);
        }
        
        Ok(())
    }
    
    pub fn get_results(&self) -> HashMap<String, BenchmarkResult> {
        self.results.read().unwrap().clone()
    }
    
    pub fn generate_report(&self) -> String {
        let results = self.get_results();
        let mut report = String::new();
        
        report.push_str("# 性能基准测试报告\n\n");
        
        for (name, result) in results {
            report.push_str(&format!("## {}\n", name));
            report.push_str(&format!("- 执行时间: {:?}\n", result.duration));
            report.push_str(&format!("- 测试时间: {}\n", result.timestamp));
            report.push_str("\n");
        }
        
        report
    }
}

#[derive(Debug, Clone)]
pub struct BenchmarkResult {
    pub name: String,
    pub duration: Duration,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}
```

## 3. 性能监控工具

### 3.1 实时性能监控

```rust
// 实时性能监控
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::time::{Duration, Instant};
use tokio::time::interval;

pub struct RealTimeMonitor {
    metrics: Arc<RwLock<SystemMetrics>>,
    start_time: Instant,
    sample_interval: Duration,
}

#[derive(Debug, Clone)]
pub struct SystemMetrics {
    pub cpu_usage: f64,
    pub memory_usage: usize,
    pub disk_io: DiskIOMetrics,
    pub network_io: NetworkIOMetrics,
    pub request_metrics: RequestMetrics,
}

#[derive(Debug, Clone)]
pub struct DiskIOMetrics {
    pub read_bytes: u64,
    pub write_bytes: u64,
    pub read_ops: u64,
    pub write_ops: u64,
}

#[derive(Debug, Clone)]
pub struct NetworkIOMetrics {
    pub bytes_sent: u64,
    pub bytes_received: u64,
    pub packets_sent: u64,
    pub packets_received: u64,
}

#[derive(Debug, Clone)]
pub struct RequestMetrics {
    pub total_requests: u64,
    pub successful_requests: u64,
    pub failed_requests: u64,
    pub average_response_time: Duration,
    pub requests_per_second: f64,
}

impl RealTimeMonitor {
    pub fn new(sample_interval: Duration) -> Self {
        Self {
            metrics: Arc::new(RwLock::new(SystemMetrics {
                cpu_usage: 0.0,
                memory_usage: 0,
                disk_io: DiskIOMetrics {
                    read_bytes: 0,
                    write_bytes: 0,
                    read_ops: 0,
                    write_ops: 0,
                },
                network_io: NetworkIOMetrics {
                    bytes_sent: 0,
                    bytes_received: 0,
                    packets_sent: 0,
                    packets_received: 0,
                },
                request_metrics: RequestMetrics {
                    total_requests: 0,
                    successful_requests: 0,
                    failed_requests: 0,
                    average_response_time: Duration::ZERO,
                    requests_per_second: 0.0,
                },
            })),
            start_time: Instant::now(),
            sample_interval,
        }
    }
    
    pub fn start_monitoring(&self) {
        let monitor = self.clone();
        tokio::spawn(async move {
            let mut interval = interval(monitor.sample_interval);
            
            loop {
                interval.tick().await;
                monitor.update_metrics().await;
            }
        });
    }
    
    async fn update_metrics(&self) {
        let mut metrics = self.metrics.write().unwrap();
        
        // 更新CPU使用率
        metrics.cpu_usage = self.get_cpu_usage().await;
        
        // 更新内存使用量
        metrics.memory_usage = self.get_memory_usage().await;
        
        // 更新磁盘IO
        metrics.disk_io = self.get_disk_io().await;
        
        // 更新网络IO
        metrics.network_io = self.get_network_io().await;
        
        // 更新请求指标
        metrics.request_metrics = self.get_request_metrics().await;
    }
    
    async fn get_cpu_usage(&self) -> f64 {
        // 实现CPU使用率获取逻辑
        50.0 // 模拟值
    }
    
    async fn get_memory_usage(&self) -> usize {
        // 实现内存使用量获取逻辑
        1024 * 1024 * 100 // 模拟值：100MB
    }
    
    async fn get_disk_io(&self) -> DiskIOMetrics {
        // 实现磁盘IO获取逻辑
        DiskIOMetrics {
            read_bytes: 1024 * 1024,
            write_bytes: 512 * 1024,
            read_ops: 100,
            write_ops: 50,
        }
    }
    
    async fn get_network_io(&self) -> NetworkIOMetrics {
        // 实现网络IO获取逻辑
        NetworkIOMetrics {
            bytes_sent: 1024 * 1024,
            bytes_received: 2 * 1024 * 1024,
            packets_sent: 1000,
            packets_received: 2000,
        }
    }
    
    async fn get_request_metrics(&self) -> RequestMetrics {
        // 实现请求指标获取逻辑
        RequestMetrics {
            total_requests: 1000,
            successful_requests: 950,
            failed_requests: 50,
            average_response_time: Duration::from_millis(100),
            requests_per_second: 10.0,
        }
    }
    
    pub fn get_metrics(&self) -> SystemMetrics {
        self.metrics.read().unwrap().clone()
    }
    
    pub fn record_request(&self, success: bool, response_time: Duration) {
        let mut metrics = self.metrics.write().unwrap();
        metrics.request_metrics.total_requests += 1;
        
        if success {
            metrics.request_metrics.successful_requests += 1;
        } else {
            metrics.request_metrics.failed_requests += 1;
        }
        
        // 更新平均响应时间
        let total_time = metrics.request_metrics.average_response_time * 
            (metrics.request_metrics.total_requests - 1) as u32 + response_time;
        metrics.request_metrics.average_response_time = 
            total_time / metrics.request_metrics.total_requests as u32;
        
        // 更新每秒请求数
        let uptime = self.start_time.elapsed();
        metrics.request_metrics.requests_per_second = 
            metrics.request_metrics.total_requests as f64 / uptime.as_secs_f64();
    }
}
```

## 4. 使用示例

### 4.1 性能分析示例

```rust
// 性能分析示例
use std::time::Duration;

async fn example_performance_analysis() {
    let profiler = CPUProfiler::new();
    
    // 分析函数性能
    profiler.start_profile("database_query");
    // 模拟数据库查询
    tokio::time::sleep(Duration::from_millis(100)).await;
    profiler.end_profile("database_query");
    
    // 分析API调用性能
    profiler.start_profile("api_call");
    // 模拟API调用
    tokio::time::sleep(Duration::from_millis(50)).await;
    profiler.end_profile("api_call");
    
    // 获取性能统计
    let stats = profiler.get_stats();
    for (name, stat) in stats {
        println!("{}: {:?}", name, stat);
    }
}
```

### 4.2 基准测试示例

```rust
// 基准测试示例
async fn example_benchmark() {
    let mut runner = BenchmarkRunner::new();
    
    // 添加基准测试
    runner.add_benchmark(Box::new(FunctionBenchmark::new(
        "vector_operations".to_string(),
        || {
            let mut vec = Vec::new();
            for i in 0..1000 {
                vec.push(i);
            }
            Ok(())
        },
        1000,
    )));
    
    // 运行基准测试
    runner.run_all().await.unwrap();
    
    // 生成报告
    let report = runner.generate_report();
    println!("{}", report);
}
```

## 5. 最佳实践

### 5.1 性能分析策略

- **定期分析**: 定期进行性能分析
- **关键路径**: 重点关注关键路径的性能
- **瓶颈识别**: 快速识别性能瓶颈
- **持续优化**: 持续优化性能

### 5.2 优化技巧

- **算法优化**: 选择更高效的算法
- **数据结构优化**: 选择合适的数据结构
- **内存优化**: 减少内存分配和复制
- **并发优化**: 充分利用并发处理

### 5.3 监控策略

- **实时监控**: 实时监控系统性能
- **告警机制**: 设置性能告警阈值
- **趋势分析**: 分析性能趋势
- **容量规划**: 基于监控数据进行容量规划

---

**文档版本**: v1.0  
**最后更新**: 2025-01-XX  
**维护者**: 工具团队
