# å¾®æœåŠ¡æ€§èƒ½åŸºå‡†æµ‹è¯•

> åŸºäºRust 1.90çš„å¾®æœåŠ¡æ€§èƒ½åŸºå‡†æµ‹è¯•ä¸è°ƒä¼˜å®è·µ

## ğŸ“‹ æ¦‚è¿°

æ€§èƒ½åŸºå‡†æµ‹è¯•æ˜¯å¾®æœåŠ¡æ¶æ„ä¼˜åŒ–çš„é‡è¦ç¯èŠ‚ã€‚æœ¬æŒ‡å—å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨ç°ä»£æ€§èƒ½æµ‹è¯•å·¥å…·å¯¹Rustå¾®æœåŠ¡è¿›è¡Œå…¨é¢çš„æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬å»¶è¿Ÿã€ååé‡ã€èµ„æºä½¿ç”¨ç‡ç­‰å…³é”®æŒ‡æ ‡çš„æµ‹é‡å’Œåˆ†æã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- æŒæ¡å¾®æœåŠ¡æ€§èƒ½æµ‹è¯•çš„æ–¹æ³•å’Œå·¥å…·
- å­¦ä¼šè®¾è®¡å’Œå®æ–½æ€§èƒ½åŸºå‡†æµ‹è¯•
- äº†è§£æ€§èƒ½ç“¶é¢ˆè¯†åˆ«å’Œä¼˜åŒ–ç­–ç•¥
- å®ç°è‡ªåŠ¨åŒ–çš„æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦

## ğŸ“š å†…å®¹å¤§çº²

## ğŸ”§ åŸºç¡€æ¦‚å¿µ

### æ€§èƒ½æµ‹è¯•ç±»å‹

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ€§èƒ½æµ‹è¯•ç±»å‹               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è´Ÿè½½æµ‹è¯• (Load Testing)             â”‚
â”‚  â”œâ”€ æ­£å¸¸è´Ÿè½½ä¸‹çš„æ€§èƒ½è¡¨ç°             â”‚
â”‚  â””â”€ éªŒè¯ç³»ç»Ÿåœ¨é¢„æœŸè´Ÿè½½ä¸‹çš„è¡Œä¸º       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å‹åŠ›æµ‹è¯• (Stress Testing)           â”‚
â”‚  â”œâ”€ è¶…å‡ºæ­£å¸¸è´Ÿè½½çš„æµ‹è¯•               â”‚
â”‚  â””â”€ ç¡®å®šç³»ç»Ÿçš„æé™å®¹é‡               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å³°å€¼æµ‹è¯• (Spike Testing)            â”‚
â”‚  â”œâ”€ çªç„¶å¢åŠ çš„è´Ÿè½½æµ‹è¯•               â”‚
â”‚  â””â”€ éªŒè¯ç³»ç»Ÿçš„å¼¹æ€§æ¢å¤èƒ½åŠ›           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å®¹é‡æµ‹è¯• (Volume Testing)           â”‚
â”‚  â”œâ”€ å¤§é‡æ•°æ®çš„å¤„ç†èƒ½åŠ›æµ‹è¯•           â”‚
â”‚  â””â”€ éªŒè¯ç³»ç»Ÿçš„æ•°æ®å¤„ç†æé™           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®æ€§èƒ½æŒ‡æ ‡

1. **å»¶è¿ŸæŒ‡æ ‡**
   - å“åº”æ—¶é—´ (Response Time)
   - å»¶è¿Ÿåˆ†å¸ƒ (Latency Distribution)
   - ç™¾åˆ†ä½æ•°å»¶è¿Ÿ (Percentile Latency)

2. **ååé‡æŒ‡æ ‡**
   - è¯·æ±‚é€Ÿç‡ (Request Rate)
   - äº‹åŠ¡é€Ÿç‡ (Transaction Rate)
   - æ•°æ®å¤„ç†é€Ÿç‡ (Data Processing Rate)

3. **èµ„æºä½¿ç”¨æŒ‡æ ‡**
   - CPUä½¿ç”¨ç‡ (CPU Utilization)
   - å†…å­˜ä½¿ç”¨ç‡ (Memory Usage)
   - ç½‘ç»œå¸¦å®½ (Network Bandwidth)
   - ç£ç›˜I/O (Disk I/O)

## ğŸ› ï¸ æµ‹è¯•å·¥å…·é€‰æ‹©

### è´Ÿè½½æµ‹è¯•å·¥å…·

| å·¥å…· | è¯­è¨€ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| wrk | C | é«˜æ€§èƒ½ã€è½»é‡çº§ | HTTP APIæµ‹è¯• |
| hey | Go | ç®€å•æ˜“ç”¨ã€åŠŸèƒ½ä¸°å¯Œ | å¿«é€Ÿæ€§èƒ½æµ‹è¯• |
| Artillery | Node.js | é…ç½®çµæ´»ã€æ”¯æŒå¤æ‚åœºæ™¯ | å¤æ‚è´Ÿè½½æµ‹è¯• |
| JMeter | Java | åŠŸèƒ½å…¨é¢ã€GUIç•Œé¢ | ä¼ä¸šçº§æµ‹è¯• |
| k6 | JavaScript | ç°ä»£å·¥å…·ã€äº‘åŸç”Ÿ | CI/CDé›†æˆ |

### ç›‘æ§å·¥å…·

| å·¥å…· | ç±»å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| Prometheus | æŒ‡æ ‡æ”¶é›† | æ—¶é—´åºåˆ—æ•°æ®åº“ | ç³»ç»Ÿç›‘æ§ |
| Grafana | å¯è§†åŒ– | ä¸°å¯Œçš„ä»ªè¡¨æ¿ | æ•°æ®å±•ç¤º |
| Jaeger | åˆ†å¸ƒå¼è¿½è¸ª | è¯·æ±‚é“¾è·¯è¿½è¸ª | æ€§èƒ½åˆ†æ |
| FlameGraph | æ€§èƒ½åˆ†æ | CPUç«ç„°å›¾ | ç“¶é¢ˆå®šä½ |

## ğŸ¯ åŸºå‡†æµ‹è¯•è®¾è®¡

### æµ‹è¯•ç¯å¢ƒé…ç½®

```yaml
# docker-compose.performance.yml
version: '3.8'

services:
  # å¾®æœåŠ¡å®ä¾‹
  user-service:
    build: ./services/user-service
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=info
      - DATABASE_URL=postgresql://user:pass@postgres:5432/users
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  order-service:
    build: ./services/order-service
    ports:
      - "8081:8080"
    environment:
      - RUST_LOG=info
      - DATABASE_URL=postgresql://user:pass@postgres:5432/orders
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G

  # æ•°æ®åº“
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=testdb
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # ç›‘æ§ç³»ç»Ÿ
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  postgres_data:
```

### æµ‹è¯•åœºæ™¯è®¾è®¡

```yaml
# artillery-config.yml
config:
  target: 'http://localhost:8080'
  phases:
    # é¢„çƒ­é˜¶æ®µ
    - duration: 60
      arrivalRate: 10
      name: "Warm up"
    
    # æ­£å¸¸è´Ÿè½½
    - duration: 300
      arrivalRate: 50
      name: "Normal load"
    
    # å³°å€¼è´Ÿè½½
    - duration: 120
      arrivalRate: 100
      name: "Peak load"
    
    # å‹åŠ›æµ‹è¯•
    - duration: 180
      arrivalRate: 200
      name: "Stress test"

scenarios:
  - name: "User CRUD operations"
    weight: 40
    flow:
      - post:
          url: "/users"
          json:
            name: "Test User {{ $randomString() }}"
            email: "test{{ $randomString() }}@example.com"
          capture:
            - json: "$.id"
              as: "userId"
      
      - get:
          url: "/users/{{ userId }}"
      
      - put:
          url: "/users/{{ userId }}"
          json:
            name: "Updated User {{ $randomString() }}"
      
      - delete:
          url: "/users/{{ userId }}"

  - name: "User list operations"
    weight: 30
    flow:
      - get:
          url: "/users"
          qs:
            page: "{{ $randomInt(1, 10) }}"
            limit: "{{ $randomInt(10, 100) }}"

  - name: "Health check"
    weight: 30
    flow:
      - get:
          url: "/health"
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡æµ‹é‡

### Rustæ€§èƒ½ç›‘æ§å®ç°

```rust
// src/metrics.rs
use prometheus::{
    Counter, Histogram, Gauge, Registry, 
    Encoder, TextEncoder, register_counter,
    register_histogram, register_gauge
};
use std::time::Instant;
use axum::{
    extract::Request,
    middleware::Next,
    response::Response,
};

pub struct Metrics {
    pub request_counter: Counter,
    pub request_duration: Histogram,
    pub active_connections: Gauge,
    pub memory_usage: Gauge,
    pub cpu_usage: Gauge,
}

impl Metrics {
    pub fn new() -> Self {
        let request_counter = register_counter!(
            "http_requests_total",
            "Total number of HTTP requests"
        ).unwrap();

        let request_duration = register_histogram!(
            "http_request_duration_seconds",
            "HTTP request duration in seconds"
        ).unwrap();

        let active_connections = register_gauge!(
            "http_active_connections",
            "Number of active HTTP connections"
        ).unwrap();

        let memory_usage = register_gauge!(
            "memory_usage_bytes",
            "Memory usage in bytes"
        ).unwrap();

        let cpu_usage = register_gauge!(
            "cpu_usage_percent",
            "CPU usage percentage"
        ).unwrap();

        Self {
            request_counter,
            request_duration,
            active_connections,
            memory_usage,
            cpu_usage,
        }
    }

    pub async fn middleware(
        metrics: Metrics,
        request: Request,
        next: Next,
    ) -> Response {
        let start = Instant::now();
        metrics.active_connections.inc();
        
        let response = next.run(request).await;
        
        let duration = start.elapsed();
        metrics.request_duration.observe(duration.as_secs_f64());
        metrics.request_counter.inc();
        metrics.active_connections.dec();
        
        response
    }

    pub fn update_system_metrics(&self) {
        // æ›´æ–°å†…å­˜ä½¿ç”¨ç‡
        if let Ok(memory_info) = get_memory_info() {
            self.memory_usage.set(memory_info.used as f64);
        }
        
        // æ›´æ–°CPUä½¿ç”¨ç‡
        if let Ok(cpu_usage) = get_cpu_usage() {
            self.cpu_usage.set(cpu_usage);
        }
    }
}

fn get_memory_info() -> Result<MemoryInfo, Box<dyn std::error::Error>> {
    use sysinfo::{System, SystemExt, ProcessExt};
    
    let mut sys = System::new_all();
    sys.refresh_all();
    
    let process = sys.processes()
        .values()
        .find(|p| p.pid() == std::process::id() as i32)
        .ok_or("Process not found")?;
    
    Ok(MemoryInfo {
        used: process.memory(),
        total: sys.total_memory(),
    })
}

fn get_cpu_usage() -> Result<f64, Box<dyn std::error::Error>> {
    use sysinfo::{System, SystemExt, ProcessExt};
    
    let mut sys = System::new_all();
    sys.refresh_all();
    
    let process = sys.processes()
        .values()
        .find(|p| p.pid() == std::process::id() as i32)
        .ok_or("Process not found")?;
    
    Ok(process.cpu_usage() as f64)
}

#[derive(Debug)]
struct MemoryInfo {
    used: u64,
    total: u64,
}
```

### æ€§èƒ½æµ‹è¯•è„šæœ¬

```rust
// src/benchmark.rs
use std::time::{Duration, Instant};
use tokio::time::sleep;
use reqwest::Client;
use serde_json::json;
use tracing::{info, error};

pub struct BenchmarkRunner {
    client: Client,
    base_url: String,
    concurrency: usize,
    duration: Duration,
}

impl BenchmarkRunner {
    pub fn new(base_url: String, concurrency: usize, duration: Duration) -> Self {
        let client = Client::new();
        Self {
            client,
            base_url,
            concurrency,
            duration,
        }
    }

    pub async fn run_benchmark(&self) -> BenchmarkResults {
        info!("å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•");
        info!("å¹¶å‘æ•°: {}, æŒç»­æ—¶é—´: {:?}", self.concurrency, self.duration);

        let start_time = Instant::now();
        let mut tasks = Vec::new();

        // å¯åŠ¨å¹¶å‘ä»»åŠ¡
        for i in 0..self.concurrency {
            let client = self.client.clone();
            let base_url = self.base_url.clone();
            let task = tokio::spawn(async move {
                Self::worker_task(client, base_url, i).await
            });
            tasks.push(task);
        }

        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        let mut all_results = Vec::new();
        for task in tasks {
            if let Ok(results) = task.await {
                all_results.extend(results);
            }
        }

        let total_duration = start_time.elapsed();
        BenchmarkResults::from_requests(all_results, total_duration)
    }

    async fn worker_task(
        client: Client,
        base_url: String,
        worker_id: usize,
    ) -> Vec<RequestResult> {
        let mut results = Vec::new();
        let start_time = Instant::now();
        let mut request_count = 0;

        while start_time.elapsed() < Duration::from_secs(300) { // 5åˆ†é’Ÿæµ‹è¯•
            let request_start = Instant::now();
            
            // æ‰§è¡Œä¸åŒç±»å‹çš„è¯·æ±‚
            let result = match request_count % 4 {
                0 => Self::create_user(&client, &base_url).await,
                1 => Self::get_user(&client, &base_url).await,
                2 => Self::list_users(&client, &base_url).await,
                3 => Self::health_check(&client, &base_url).await,
                _ => unreachable!(),
            };

            let duration = request_start.elapsed();
            results.push(RequestResult {
                worker_id,
                request_type: result.request_type,
                duration,
                success: result.success,
                status_code: result.status_code,
            });

            request_count += 1;
            
            // æ§åˆ¶è¯·æ±‚é¢‘ç‡
            sleep(Duration::from_millis(100)).await;
        }

        results
    }

    async fn create_user(client: &Client, base_url: &str) -> RequestResult {
        let start = Instant::now();
        let payload = json!({
            "name": format!("Test User {}", uuid::Uuid::new_v4()),
            "email": format!("test{}@example.com", uuid::Uuid::new_v4())
        });

        match client
            .post(&format!("{}/users", base_url))
            .json(&payload)
            .send()
            .await
        {
            Ok(response) => RequestResult {
                request_type: "POST /users".to_string(),
                duration: start.elapsed(),
                success: response.status().is_success(),
                status_code: response.status().as_u16(),
            },
            Err(e) => {
                error!("åˆ›å»ºç”¨æˆ·è¯·æ±‚å¤±è´¥: {}", e);
                RequestResult {
                    request_type: "POST /users".to_string(),
                    duration: start.elapsed(),
                    success: false,
                    status_code: 0,
                }
            }
        }
    }

    async fn get_user(client: &Client, base_url: &str) -> RequestResult {
        let start = Instant::now();
        let user_id = "test-user-id"; // ç®€åŒ–å¤„ç†

        match client
            .get(&format!("{}/users/{}", base_url, user_id))
            .send()
            .await
        {
            Ok(response) => RequestResult {
                request_type: "GET /users/{id}".to_string(),
                duration: start.elapsed(),
                success: response.status().is_success(),
                status_code: response.status().as_u16(),
            },
            Err(e) => {
                error!("è·å–ç”¨æˆ·è¯·æ±‚å¤±è´¥: {}", e);
                RequestResult {
                    request_type: "GET /users/{id}".to_string(),
                    duration: start.elapsed(),
                    success: false,
                    status_code: 0,
                }
            }
        }
    }

    async fn list_users(client: &Client, base_url: &str) -> RequestResult {
        let start = Instant::now();

        match client
            .get(&format!("{}/users", base_url))
            .query(&[("page", "1"), ("limit", "10")])
            .send()
            .await
        {
            Ok(response) => RequestResult {
                request_type: "GET /users".to_string(),
                duration: start.elapsed(),
                success: response.status().is_success(),
                status_code: response.status().as_u16(),
            },
            Err(e) => {
                error!("è·å–ç”¨æˆ·åˆ—è¡¨è¯·æ±‚å¤±è´¥: {}", e);
                RequestResult {
                    request_type: "GET /users".to_string(),
                    duration: start.elapsed(),
                    success: false,
                    status_code: 0,
                }
            }
        }
    }

    async fn health_check(client: &Client, base_url: &str) -> RequestResult {
        let start = Instant::now();

        match client
            .get(&format!("{}/health", base_url))
            .send()
            .await
        {
            Ok(response) => RequestResult {
                request_type: "GET /health".to_string(),
                duration: start.elapsed(),
                success: response.status().is_success(),
                status_code: response.status().as_u16(),
            },
            Err(e) => {
                error!("å¥åº·æ£€æŸ¥è¯·æ±‚å¤±è´¥: {}", e);
                RequestResult {
                    request_type: "GET /health".to_string(),
                    duration: start.elapsed(),
                    success: false,
                    status_code: 0,
                }
            }
        }
    }
}

#[derive(Debug, Clone)]
pub struct RequestResult {
    pub worker_id: usize,
    pub request_type: String,
    pub duration: Duration,
    pub success: bool,
    pub status_code: u16,
}

#[derive(Debug)]
pub struct BenchmarkResults {
    pub total_requests: usize,
    pub successful_requests: usize,
    pub failed_requests: usize,
    pub total_duration: Duration,
    pub requests_per_second: f64,
    pub average_latency: Duration,
    pub min_latency: Duration,
    pub max_latency: Duration,
    pub p50_latency: Duration,
    pub p95_latency: Duration,
    pub p99_latency: Duration,
    pub error_rate: f64,
}

impl BenchmarkResults {
    fn from_requests(requests: Vec<RequestResult>, total_duration: Duration) -> Self {
        let total_requests = requests.len();
        let successful_requests = requests.iter().filter(|r| r.success).count();
        let failed_requests = total_requests - successful_requests;
        
        let mut latencies: Vec<Duration> = requests.iter().map(|r| r.duration).collect();
        latencies.sort();
        
        let total_latency: Duration = latencies.iter().sum();
        let average_latency = if !latencies.is_empty() {
            Duration::from_nanos(total_latency.as_nanos() as u64 / latencies.len() as u64)
        } else {
            Duration::ZERO
        };
        
        let min_latency = latencies.first().copied().unwrap_or(Duration::ZERO);
        let max_latency = latencies.last().copied().unwrap_or(Duration::ZERO);
        
        let p50_latency = Self::percentile(&latencies, 50.0);
        let p95_latency = Self::percentile(&latencies, 95.0);
        let p99_latency = Self::percentile(&latencies, 99.0);
        
        let requests_per_second = if total_duration.as_secs() > 0 {
            total_requests as f64 / total_duration.as_secs() as f64
        } else {
            0.0
        };
        
        let error_rate = if total_requests > 0 {
            failed_requests as f64 / total_requests as f64 * 100.0
        } else {
            0.0
        };
        
        Self {
            total_requests,
            successful_requests,
            failed_requests,
            total_duration,
            requests_per_second,
            average_latency,
            min_latency,
            max_latency,
            p50_latency,
            p95_latency,
            p99_latency,
            error_rate,
        }
    }
    
    fn percentile(latencies: &[Duration], p: f64) -> Duration {
        if latencies.is_empty() {
            return Duration::ZERO;
        }
        
        let index = ((p / 100.0) * (latencies.len() - 1) as f64).round() as usize;
        latencies[index.min(latencies.len() - 1)]
    }
    
    pub fn print_summary(&self) {
        println!("=== æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ ===");
        println!("æ€»è¯·æ±‚æ•°: {}", self.total_requests);
        println!("æˆåŠŸè¯·æ±‚æ•°: {}", self.successful_requests);
        println!("å¤±è´¥è¯·æ±‚æ•°: {}", self.failed_requests);
        println!("é”™è¯¯ç‡: {:.2}%", self.error_rate);
        println!("æ€»è€—æ—¶: {:?}", self.total_duration);
        println!("è¯·æ±‚é€Ÿç‡: {:.2} req/s", self.requests_per_second);
        println!("å¹³å‡å»¶è¿Ÿ: {:?}", self.average_latency);
        println!("æœ€å°å»¶è¿Ÿ: {:?}", self.min_latency);
        println!("æœ€å¤§å»¶è¿Ÿ: {:?}", self.max_latency);
        println!("P50å»¶è¿Ÿ: {:?}", self.p50_latency);
        println!("P95å»¶è¿Ÿ: {:?}", self.p95_latency);
        println!("P99å»¶è¿Ÿ: {:?}", self.p99_latency);
    }
}
```

## ğŸ” ç“¶é¢ˆåˆ†æ

### æ€§èƒ½åˆ†æå·¥å…·

```rust
// src/profiling.rs
use std::time::Instant;
use tracing::{info, warn, error};

pub struct PerformanceProfiler {
    start_time: Instant,
    checkpoints: Vec<(String, Instant)>,
}

impl PerformanceProfiler {
    pub fn new() -> Self {
        Self {
            start_time: Instant::now(),
            checkpoints: Vec::new(),
        }
    }
    
    pub fn checkpoint(&mut self, name: &str) {
        let now = Instant::now();
        self.checkpoints.push((name.to_string(), now));
        info!("æ£€æŸ¥ç‚¹: {} - è€—æ—¶: {:?}", name, now.duration_since(self.start_time));
    }
    
    pub fn analyze(&self) -> PerformanceAnalysis {
        let mut analysis = PerformanceAnalysis::new();
        
        for (i, (name, checkpoint)) in self.checkpoints.iter().enumerate() {
            let duration = if i == 0 {
                checkpoint.duration_since(self.start_time)
            } else {
                checkpoint.duration_since(self.checkpoints[i - 1].1)
            };
            
            analysis.add_segment(name.clone(), duration);
        }
        
        analysis
    }
}

#[derive(Debug)]
pub struct PerformanceAnalysis {
    pub segments: Vec<(String, std::time::Duration)>,
    pub total_duration: std::time::Duration,
    pub slowest_segment: Option<(String, std::time::Duration)>,
}

impl PerformanceAnalysis {
    fn new() -> Self {
        Self {
            segments: Vec::new(),
            total_duration: std::time::Duration::ZERO,
            slowest_segment: None,
        }
    }
    
    fn add_segment(&mut self, name: String, duration: std::time::Duration) {
        self.segments.push((name, duration));
        self.total_duration += duration;
        
        if let Some((_, slowest_duration)) = &self.slowest_segment {
            if duration > *slowest_duration {
                self.slowest_segment = Some((name, duration));
            }
        } else {
            self.slowest_segment = Some((name, duration));
        }
    }
    
    pub fn print_analysis(&self) {
        println!("=== æ€§èƒ½åˆ†ææŠ¥å‘Š ===");
        println!("æ€»è€—æ—¶: {:?}", self.total_duration);
        
        if let Some((name, duration)) = &self.slowest_segment {
            println!("æœ€æ…¢æ®µ: {} - {:?}", name, duration);
        }
        
        println!("\nå„æ®µè€—æ—¶:");
        for (name, duration) in &self.segments {
            let percentage = (duration.as_nanos() as f64 / self.total_duration.as_nanos() as f64) * 100.0;
            println!("  {}: {:?} ({:.1}%)", name, duration, percentage);
        }
    }
}
```

### å†…å­˜åˆ†æ

```rust
// src/memory_analysis.rs
use std::alloc::{GlobalAlloc, Layout, System};
use std::sync::atomic::{AtomicUsize, Ordering};

pub struct MemoryTracker {
    allocated: AtomicUsize,
    deallocated: AtomicUsize,
}

impl MemoryTracker {
    pub fn new() -> Self {
        Self {
            allocated: AtomicUsize::new(0),
            deallocated: AtomicUsize::new(0),
        }
    }
    
    pub fn get_current_usage(&self) -> usize {
        self.allocated.load(Ordering::Relaxed) - self.deallocated.load(Ordering::Relaxed)
    }
    
    pub fn get_total_allocated(&self) -> usize {
        self.allocated.load(Ordering::Relaxed)
    }
    
    pub fn get_total_deallocated(&self) -> usize {
        self.deallocated.load(Ordering::Relaxed)
    }
}

pub struct TrackingAllocator {
    tracker: &'static MemoryTracker,
}

impl TrackingAllocator {
    pub fn new(tracker: &'static MemoryTracker) -> Self {
        Self { tracker }
    }
}

unsafe impl GlobalAlloc for TrackingAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let ptr = System.alloc(layout);
        if !ptr.is_null() {
            self.tracker.allocated.fetch_add(layout.size(), Ordering::Relaxed);
        }
        ptr
    }
    
    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        self.tracker.deallocated.fetch_add(layout.size(), Ordering::Relaxed);
        System.dealloc(ptr, layout);
    }
}
```

## âš¡ ä¼˜åŒ–ç­–ç•¥

### 1. ä»£ç ä¼˜åŒ–

```rust
// src/optimizations.rs
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;

// è¿æ¥æ± ä¼˜åŒ–
pub struct ConnectionPool<T> {
    connections: Arc<RwLock<Vec<T>>>,
    max_size: usize,
    min_size: usize,
}

impl<T> ConnectionPool<T> {
    pub fn new(max_size: usize, min_size: usize) -> Self {
        Self {
            connections: Arc::new(RwLock::new(Vec::with_capacity(max_size))),
            max_size,
            min_size,
        }
    }
    
    pub async fn get_connection(&self) -> Option<T> {
        let mut connections = self.connections.write().await;
        connections.pop()
    }
    
    pub async fn return_connection(&self, connection: T) {
        let mut connections = self.connections.write().await;
        if connections.len() < self.max_size {
            connections.push(connection);
        }
    }
}

// ç¼“å­˜ä¼˜åŒ–
pub struct LruCache<K, V> {
    cache: Arc<RwLock<HashMap<K, V>>>,
    max_size: usize,
}

impl<K, V> LruCache<K, V>
where
    K: Clone + std::hash::Hash + Eq,
    V: Clone,
{
    pub fn new(max_size: usize) -> Self {
        Self {
            cache: Arc::new(RwLock::new(HashMap::new())),
            max_size,
        }
    }
    
    pub async fn get(&self, key: &K) -> Option<V> {
        let cache = self.cache.read().await;
        cache.get(key).cloned()
    }
    
    pub async fn insert(&self, key: K, value: V) {
        let mut cache = self.cache.write().await;
        if cache.len() >= self.max_size {
            // ç®€å•çš„LRUå®ç°ï¼šç§»é™¤ç¬¬ä¸€ä¸ªå…ƒç´ 
            if let Some(first_key) = cache.keys().next().cloned() {
                cache.remove(&first_key);
            }
        }
        cache.insert(key, value);
    }
}

// æ‰¹å¤„ç†ä¼˜åŒ–
pub struct BatchProcessor<T> {
    batch_size: usize,
    timeout: std::time::Duration,
    buffer: Arc<RwLock<Vec<T>>>,
}

impl<T> BatchProcessor<T> {
    pub fn new(batch_size: usize, timeout: std::time::Duration) -> Self {
        Self {
            batch_size,
            timeout,
            buffer: Arc::new(RwLock::new(Vec::new())),
        }
    }
    
    pub async fn add_item(&self, item: T) -> bool {
        let mut buffer = self.buffer.write().await;
        buffer.push(item);
        
        if buffer.len() >= self.batch_size {
            // è§¦å‘æ‰¹å¤„ç†
            let batch = buffer.drain(..).collect::<Vec<_>>();
            drop(buffer);
            self.process_batch(batch).await;
            true
        } else {
            false
        }
    }
    
    async fn process_batch(&self, batch: Vec<T>) {
        // æ‰¹å¤„ç†é€»è¾‘
        info!("å¤„ç†æ‰¹æ¬¡ï¼Œå¤§å°: {}", batch.len());
    }
}
```

### 2. ç³»ç»Ÿä¼˜åŒ–

```rust
// src/system_optimizations.rs
use std::thread;
use std::sync::atomic::{AtomicUsize, Ordering};

pub struct SystemOptimizer {
    thread_pool_size: AtomicUsize,
}

impl SystemOptimizer {
    pub fn new() -> Self {
        Self {
            thread_pool_size: AtomicUsize::new(num_cpus::get()),
        }
    }
    
    pub fn optimize_thread_pool(&self) {
        let cpu_count = num_cpus::get();
        let optimal_size = cpu_count * 2; // I/Oå¯†é›†å‹ä»»åŠ¡
        
        self.thread_pool_size.store(optimal_size, Ordering::Relaxed);
        
        // è®¾ç½®çº¿ç¨‹äº²å’Œæ€§
        self.set_thread_affinity();
    }
    
    fn set_thread_affinity(&self) {
        // è®¾ç½®çº¿ç¨‹äº²å’Œæ€§ä»¥ä¼˜åŒ–CPUç¼“å­˜
        thread::spawn(|| {
            // ç»‘å®šåˆ°ç‰¹å®šCPUæ ¸å¿ƒ
            #[cfg(target_os = "linux")]
            {
                use std::process::Command;
                let pid = std::process::id();
                let cpu_id = 0;
                let _ = Command::new("taskset")
                    .args(&["-cp", &format!("{}", cpu_id), &format!("{}", pid)])
                    .output();
            }
        });
    }
    
    pub fn optimize_memory(&self) {
        // å†…å­˜ä¼˜åŒ–é…ç½®
        self.set_memory_limits();
        self.enable_memory_pool();
    }
    
    fn set_memory_limits(&self) {
        // è®¾ç½®å†…å­˜é™åˆ¶
        #[cfg(target_os = "linux")]
        {
            use std::process::Command;
            let _ = Command::new("ulimit")
                .args(&["-v", "2097152"]) // 2GBè™šæ‹Ÿå†…å­˜é™åˆ¶
                .output();
        }
    }
    
    fn enable_memory_pool(&self) {
        // å¯ç”¨å†…å­˜æ± 
        // è¿™é‡Œå¯ä»¥å®ç°è‡ªå®šä¹‰çš„å†…å­˜æ± åˆ†é…å™¨
    }
}
```

## ğŸ¤– è‡ªåŠ¨åŒ–æµ‹è¯•

### CI/CDé›†æˆ

```yaml
# .github/workflows/performance-test.yml
name: Performance Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  performance-test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: 1.90
        override: true
    
    - name: Build services
      run: |
        cd services/user-service
        cargo build --release
    
    - name: Start services
      run: |
        docker-compose -f docker-compose.performance.yml up -d
        sleep 30  # ç­‰å¾…æœåŠ¡å¯åŠ¨
    
    - name: Run performance tests
      run: |
        # å®‰è£…æµ‹è¯•å·¥å…·
        go install github.com/rakyll/hey@latest
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        hey -n 10000 -c 100 -m GET http://localhost:8080/health
        hey -n 5000 -c 50 -m POST -H "Content-Type: application/json" \
            -d '{"name":"Test User","email":"test@example.com"}' \
            http://localhost:8080/users
    
    - name: Generate performance report
      run: |
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        cargo run --bin benchmark -- --output performance-report.json
    
    - name: Upload performance report
      uses: actions/upload-artifact@v3
      with:
        name: performance-report
        path: performance-report.json
```

### æ€§èƒ½å›å½’æ£€æµ‹

```rust
// src/regression_detector.rs
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Serialize, Deserialize)]
pub struct PerformanceBaseline {
    pub metrics: HashMap<String, MetricBaseline>,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct MetricBaseline {
    pub value: f64,
    pub threshold: f64,
    pub unit: String,
}

#[derive(Debug)]
pub struct RegressionDetector {
    baseline: PerformanceBaseline,
}

impl RegressionDetector {
    pub fn new(baseline: PerformanceBaseline) -> Self {
        Self { baseline }
    }
    
    pub fn detect_regression(&self, current_metrics: &HashMap<String, f64>) -> Vec<Regression> {
        let mut regressions = Vec::new();
        
        for (metric_name, current_value) in current_metrics {
            if let Some(baseline_metric) = self.baseline.metrics.get(metric_name) {
                let deviation = (current_value - baseline_metric.value) / baseline_metric.value * 100.0;
                
                if deviation.abs() > baseline_metric.threshold {
                    regressions.push(Regression {
                        metric_name: metric_name.clone(),
                        baseline_value: baseline_metric.value,
                        current_value: *current_value,
                        deviation,
                        threshold: baseline_metric.threshold,
                        unit: baseline_metric.unit.clone(),
                    });
                }
            }
        }
        
        regressions
    }
}

#[derive(Debug)]
pub struct Regression {
    pub metric_name: String,
    pub baseline_value: f64,
    pub current_value: f64,
    pub deviation: f64,
    pub threshold: f64,
    pub unit: String,
}

impl Regression {
    pub fn is_significant(&self) -> bool {
        self.deviation.abs() > self.threshold
    }
    
    pub fn print_report(&self) {
        println!("=== æ€§èƒ½å›å½’æ£€æµ‹æŠ¥å‘Š ===");
        println!("æŒ‡æ ‡: {}", self.metric_name);
        println!("åŸºå‡†å€¼: {:.2} {}", self.baseline_value, self.unit);
        println!("å½“å‰å€¼: {:.2} {}", self.current_value, self.unit);
        println!("åå·®: {:.2}%", self.deviation);
        println!("é˜ˆå€¼: {:.2}%", self.threshold);
        println!("æ˜¯å¦æ˜¾è‘—: {}", if self.is_significant() { "æ˜¯" } else { "å¦" });
    }
}
```

## ğŸ“– æœ€ä½³å®è·µ

### 1. æµ‹è¯•è®¾è®¡åŸåˆ™

```rust
// 1. åˆ†å±‚æµ‹è¯•ç­–ç•¥
pub struct TestStrategy {
    pub unit_tests: bool,      // å•å…ƒæµ‹è¯•
    pub integration_tests: bool, // é›†æˆæµ‹è¯•
    pub performance_tests: bool, // æ€§èƒ½æµ‹è¯•
    pub load_tests: bool,      // è´Ÿè½½æµ‹è¯•
    pub stress_tests: bool,    // å‹åŠ›æµ‹è¯•
}

// 2. æµ‹è¯•æ•°æ®ç®¡ç†
pub struct TestDataManager {
    pub test_users: Vec<TestUser>,
    pub test_orders: Vec<TestOrder>,
    pub test_products: Vec<TestProduct>,
}

impl TestDataManager {
    pub fn generate_test_data(&mut self, count: usize) {
        for i in 0..count {
            self.test_users.push(TestUser {
                id: format!("user_{}", i),
                name: format!("Test User {}", i),
                email: format!("test{}@example.com", i),
            });
        }
    }
}

// 3. ç¯å¢ƒéš”ç¦»
pub struct TestEnvironment {
    pub database_url: String,
    pub redis_url: String,
    pub service_urls: HashMap<String, String>,
}

impl TestEnvironment {
    pub fn setup(&self) -> Result<(), Box<dyn std::error::Error>> {
        // è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        self.start_services()?;
        self.setup_database()?;
        self.setup_redis()?;
        Ok(())
    }
    
    pub fn teardown(&self) -> Result<(), Box<dyn std::error::Error>> {
        // æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        self.stop_services()?;
        self.cleanup_database()?;
        self.cleanup_redis()?;
        Ok(())
    }
}
```

### 2. ç›‘æ§å’Œå‘Šè­¦

```rust
// æ€§èƒ½ç›‘æ§é…ç½®
pub struct PerformanceMonitor {
    pub metrics_collector: MetricsCollector,
    pub alert_manager: AlertManager,
    pub dashboard: Dashboard,
}

impl PerformanceMonitor {
    pub fn setup_alerts(&self) {
        // å»¶è¿Ÿå‘Šè­¦
        self.alert_manager.add_alert(Alert {
            name: "High Latency".to_string(),
            condition: "p95_latency > 100ms".to_string(),
            severity: AlertSeverity::Warning,
        });
        
        // é”™è¯¯ç‡å‘Šè­¦
        self.alert_manager.add_alert(Alert {
            name: "High Error Rate".to_string(),
            condition: "error_rate > 5%".to_string(),
            severity: AlertSeverity::Critical,
        });
        
        // èµ„æºä½¿ç”¨å‘Šè­¦
        self.alert_manager.add_alert(Alert {
            name: "High CPU Usage".to_string(),
            condition: "cpu_usage > 80%".to_string(),
            severity: AlertSeverity::Warning,
        });
    }
}
```

é€šè¿‡æœ¬æŒ‡å—ï¼Œæ‚¨å¯ä»¥å»ºç«‹å®Œæ•´çš„å¾®æœåŠ¡æ€§èƒ½åŸºå‡†æµ‹è¯•ä½“ç³»ï¼Œå®ç°æ€§èƒ½ç›‘æ§ã€ç“¶é¢ˆåˆ†æå’Œä¼˜åŒ–ç­–ç•¥çš„è‡ªåŠ¨åŒ–æ‰§è¡Œã€‚
