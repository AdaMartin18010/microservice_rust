# 实际项目案例分析

> 基于 Rust 1.90 的微服务项目实战精选，涵盖电商订单与实时日志两类高频场景

## 📋 概述

本章节以两个具有代表性的生产级案例为载体，系统展示从架构设计、技术选型、核心实现到运维治理与可观测性的一体化落地路径。读者可将其作为模板，快速复制到自有业务中。

## 🎯 学习目标

- 掌握电商订单域的 Outbox + Saga 一致性落地方法
- 学会在高吞吐日志采集中实施批量、压缩、背压与分层缓存
- 建立以 RED/USE 为核心的可观测性指标体系与告警策略
- 形成“从代码到运维”的端到端工程化视角

## 📚 内容大纲

- [实际项目案例分析](#实际项目案例分析)
  - [📋 概述](#-概述)
  - [🎯 学习目标](#-学习目标)
  - [📚 内容大纲](#-内容大纲)
  - [🛒 案例A：电商订单微服务](#-案例a电商订单微服务)
    - [背景与目标](#背景与目标)
    - [技术栈与项目骨架](#技术栈与项目骨架)
    - [领域建模与状态机（示例）](#领域建模与状态机示例)
    - [一致性：Outbox + Saga 实战（要点）](#一致性outbox--saga-实战要点)
    - [API 设计与路由（Axum 片段）](#api-设计与路由axum-片段)
    - [治理：限流/熔断/灰度（策略）](#治理限流熔断灰度策略)
    - [可观测性与 SLO](#可观测性与-slo)
  - [📈 案例B：实时日志采集与分析](#-案例b实时日志采集与分析)
    - [背景与目标B](#背景与目标b)
    - [技术栈与高性能 I/O](#技术栈与高性能-io)
    - [批量/压缩/背压（要点）](#批量压缩背压要点)
    - [ClickHouse 写入（建议）](#clickhouse-写入建议)
    - [监控与容量规划](#监控与容量规划)
  - [🧭 经验总结与可复用清单](#-经验总结与可复用清单)

---

## 🛒 案例A：电商订单微服务

### 背景与目标

在高并发场景下实现可靠的下单→支付→库存→发货流程，要求：

- 订单状态可回放、可审计；
- 跨服务一致性保障（最终一致）；
- 支撑灰度与弹性治理；
- 完整的追踪与指标可观测性。

### 技术栈与项目骨架

- Web/API：Axum
- RPC：Tonic (gRPC)
- 数据库：PostgreSQL + SQLx
- 消息：Kafka（事件总线）
- 追踪：OpenTelemetry + Jaeger
- 指标：Prometheus（RED/USE）

项目结构建议：

```text
order-service/
├── src/
│   ├── api/                 # HTTP & gRPC 接口
│   ├── domain/              # 领域模型与状态机
│   ├── consistency/         # outbox/事件/事务
│   ├── saga/                # Saga 定义与执行器
│   ├── governance/          # 限流/熔断/灰度
│   ├── observability/       # tracing/metrics/healthz
│   └── infra/               # SQLx、Kafka、配置
├── migrations/              # 数据库迁移
└── Cargo.toml
```

### 领域建模与状态机（示例）

```rust
// 片段：领域状态与校验
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, PartialEq)]
pub enum OrderStatus { Pending, Confirmed, Paid, Shipped, Delivered, Cancelled, Refunded }

impl OrderStatus {
    pub fn can_transit_to(&self, next: &OrderStatus) -> bool {
        use OrderStatus::*;
        matches!((self, next),
            (Pending, Confirmed) |
            (Confirmed, Paid) |
            (Paid, Shipped) |
            (Shipped, Delivered) |
            // 允许从 Pending/Confirmed/Paid 进入 Cancelled
            (Pending, Cancelled) | (Confirmed, Cancelled) | (Paid, Cancelled) |
            // 支付后允许退款
            (Paid, Refunded)
        )
    }
}
```

### 一致性：Outbox + Saga 实战（要点）

- 同一事务内写业务表与 `outbox_events`；
- 后台出站器轮询 `outbox_events` 发布 Kafka；
- Saga 将订单校验、扣款、预留库存串成编排流，失败即补偿；
- 幂等键：以业务唯一键防止重复执行；
- 读一致：查询时优先本地写后读策略或基于事件的读模型刷新。

```rust
// 片段：Outbox 事件定义与出站处理示例
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct OutboxEvent {
    pub id: uuid::Uuid,
    pub aggregate_id: String,
    pub event_type: String,
    pub event_data: serde_json::Value,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub processed: bool,
}

pub struct OutboxStore { pub pool: sqlx::PgPool }

impl OutboxStore {
    pub async fn append(&self, e: &OutboxEvent, tx: &mut sqlx::Transaction<'_, sqlx::Postgres>) -> Result<(), sqlx::Error> {
        sqlx::query(
            "INSERT INTO outbox_events(id,aggregate_id,event_type,event_data,created_at,processed) VALUES($1,$2,$3,$4,$5,$6)"
        )
        .bind(e.id)
        .bind(&e.aggregate_id)
        .bind(&e.event_type)
        .bind(&e.event_data)
        .bind(e.created_at)
        .bind(e.processed)
        .execute(&mut **tx).await?;
        Ok(())
    }

    pub async fn fetch_unprocessed(&self, limit: i64) -> Result<Vec<OutboxEvent>, sqlx::Error> {
        let rows = sqlx::query(
            "SELECT id,aggregate_id,event_type,event_data,created_at,processed FROM outbox_events WHERE processed=false ORDER BY created_at LIMIT $1"
        ).bind(limit).fetch_all(&self.pool).await?;
        Ok(rows.into_iter().map(|r| OutboxEvent{
            id: r.get("id"), aggregate_id: r.get("aggregate_id"), event_type: r.get("event_type"),
            event_data: r.get("event_data"), created_at: r.get("created_at"), processed: r.get("processed")
        }).collect())
    }

    pub async fn mark_processed(&self, id: uuid::Uuid) -> Result<(), sqlx::Error> {
        sqlx::query("UPDATE outbox_events SET processed=true WHERE id=$1").bind(id).execute(&self.pool).await?; Ok(())
    }
}

pub struct EventPublisher { pub kafka: KafkaProducer, pub outbox: OutboxStore }

impl EventPublisher {
    pub async fn pump(&self) -> anyhow::Result<()> {
        for e in self.outbox.fetch_unprocessed(200).await? {
            self.kafka.send("order-events", &e.event_data).await?;
            self.outbox.mark_processed(e.id).await?;
        }
        Ok(())
    }
}
```

### API 设计与路由（Axum 片段）

```rust
pub fn routes(state: AppState) -> axum::Router {
    use axum::{routing::{get, post}, Router};
    Router::new()
        .route("/orders", post(create_order))
        .route("/orders/:id", get(get_order))
        .with_state(state)
}

// 处理器与错误模型骨架
#[derive(thiserror::Error, Debug)]
pub enum ApiError {
    #[error("bad request: {0}")] BadRequest(String),
    #[error("not found")] NotFound,
    #[error("internal error")] Internal,
}

impl axum::response::IntoResponse for ApiError {
    fn into_response(self) -> axum::response::Response {
        use axum::{http::StatusCode, Json};
        let (code,msg) = match self {
            ApiError::BadRequest(m) => (StatusCode::BAD_REQUEST, m),
            ApiError::NotFound => (StatusCode::NOT_FOUND, "not found".into()),
            ApiError::Internal => (StatusCode::INTERNAL_SERVER_ERROR, "internal".into()),
        };
        (code, Json(serde_json::json!({"error": msg}))).into_response()
    }
}

pub async fn create_order(
    axum::extract::State(svc): axum::extract::State<OrderService>,
    axum::Json(req): axum::Json<CreateOrderRequest>,
) -> Result<axum::Json<Order>, ApiError> {
    let order = svc.create_order(req).await.map_err(|e| {
        tracing::error!(?e, "create_order failed"); ApiError::Internal
    })?;
    Ok(axum::Json(order))
}

pub async fn get_order(
    axum::extract::State(svc): axum::extract::State<OrderService>,
    axum::extract::Path(id): axum::extract::Path<uuid::Uuid>,
) -> Result<axum::Json<Order>, ApiError> {
    match svc.get_order(id).await.map_err(|_| ApiError::Internal)? {
        Some(o) => Ok(axum::Json(o)),
        None => Err(ApiError::NotFound)
    }
}
```

### 治理：限流/熔断/灰度（策略）

- 入口限流：令牌桶基于租户/用户/路径维度；
- 客户端熔断：对支付、库存等外部调用设置熔断+退避；
- 灰度：基于标头/用户分群/百分比路由，支持快速回滚。

### 可观测性与 SLO

- 追踪：下单-支付-库存-发货链路贯通；
- RED 指标：请求速率(R)、错误率(E)、延迟(D)；
- SLO 示例：P99 延迟 < 150ms，错误率 < 0.1%，可用性 99.9%。

---

## 📈 案例B：实时日志采集与分析

### 背景与目标B

面向 TB 级日志量的实时采集、传输与入库分析，强调吞吐、成本与可扩展性：

- 入口抗压：边缘节点聚合/预处理；
- 传输高效：压缩+批量+背压；
- 冷热分层：近实时查询与历史归档分层。

### 技术栈与高性能 I/O

- 边缘入口：Actix Web（多核利用）
- 消息中间件：NATS JetStream / Kafka（二选一或并用）
- 存储：ClickHouse（列存 + MergeTree）
- 压缩：LZ4/Deflate；批量刷盘：定时 + 阈值

### 批量/压缩/背压（要点）

- 批量阈值：条数阈值或时间窗口二者择一先到即刷；
- 压缩：批量 JSON → LZ4 block 压缩后入队；
- 背压：队列水位告警 + 限流/丢弃策略（可配置）。

```rust
// NATS 发布与 ClickHouse 批量写入极简示例
pub async fn publish_nats(nc: &nats::asynk::Connection, subject: &str, batch: &[serde_json::Value]) -> anyhow::Result<()> {
    let payload = serde_json::to_vec(batch)?;
    let compressed = lz4::block::compress(&payload, None, lz4::block::CompressionMode::DEFAULT)?;
    nc.publish(subject, compressed).await?; Ok(())
}

pub async fn write_clickhouse(pool: &clickhouse_rs::Pool, batch: &[LogEntry]) -> Result<(), clickhouse_rs::errors::Error> {
    let mut handle = pool.get_handle().await?;
    let mut insert = handle.prepare("INSERT INTO logs (id,timestamp,level,message,source,tags) VALUES (?,?,?,?,?,?)").await?;
    for e in batch {
        insert.bind(&e.id).bind(&e.timestamp).bind(&e.level).bind(&e.message).bind(&e.source)
              .bind(&serde_json::to_string(&e.tags).unwrap()).execute().await?;
    }
    Ok(())
}
```

### ClickHouse 写入（建议）

- 表设计：宽表 + 常用查询字段建立索引；
- 批写：利用 `insert_many`/批量 pipeline；
- 资源：根据磁盘 IOPS 与 CPU 配额设置合并策略与并发度。

### 监控与容量规划

- 指标：入口 QPS、批量大小、压缩比、入库耗时、丢弃率；
- 预案：存储水位 > 80% 触发冷热分层与归档；
- 压测：持续压测校准批量与并发参数。

---

## 🧭 经验总结与可复用清单

- 统一基线：错误模型、追踪上下文、指标维度统一；
- 一致性优先级：先明确定义业务一致性 SLA，再选技术方案；
- 预留开关：灰度/限流/降级皆需“开关即用，回滚即撤”；
- 自动化：CI/CD + 策略化回滚，配合合成流量做回归。

---

**文档版本**: v1.0  
**创建时间**: 2025-09-29  
**更新时间**: 2025-09-29
