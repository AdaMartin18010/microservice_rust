# æ€§èƒ½ä¼˜åŒ–ä¸è°ƒä¼˜æŒ‡å—

> åŸºäºRust 1.90å’Œæœ€æ–°ä¾èµ–ç‰ˆæœ¬çš„å¾®æœåŠ¡æ€§èƒ½ä¼˜åŒ–å®Œæ•´è§£å†³æ–¹æ¡ˆ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº†å®Œæ•´çš„å¾®æœåŠ¡æ€§èƒ½ä¼˜åŒ–æŒ‡å—ï¼ŒåŒ…æ‹¬å†…å­˜ä¼˜åŒ–ã€å¹¶å‘è°ƒä¼˜ã€ç½‘ç»œä¼˜åŒ–ã€æ•°æ®åº“ä¼˜åŒ–ç­‰å…¨æ ˆæ€§èƒ½æå‡æ–¹æ¡ˆã€‚

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–ç›®æ ‡

### 1. æ ¸å¿ƒæŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | æµ‹é‡æ–¹æ³• |
|------|--------|----------|
| å“åº”æ—¶é—´ | < 100ms (P95) | åˆ†å¸ƒå¼è¿½è¸ª |
| ååé‡ | > 10,000 RPS | è´Ÿè½½æµ‹è¯• |
| å†…å­˜ä½¿ç”¨ | < 512MB | ç³»ç»Ÿç›‘æ§ |
| CPUä½¿ç”¨ç‡ | < 70% | ç³»ç»Ÿç›‘æ§ |
| é”™è¯¯ç‡ | < 0.1% | æŒ‡æ ‡æ”¶é›† |

### 2. ä¼˜åŒ–å±‚æ¬¡

```mermaid
graph TB
    A[åº”ç”¨å±‚ä¼˜åŒ–] --> B[æ¡†æ¶å±‚ä¼˜åŒ–]
    B --> C[ç³»ç»Ÿå±‚ä¼˜åŒ–]
    C --> D[ç¡¬ä»¶å±‚ä¼˜åŒ–]
    
    A --> A1[ç®—æ³•ä¼˜åŒ–]
    A --> A2[æ•°æ®ç»“æ„ä¼˜åŒ–]
    A --> A3[å†…å­˜ç®¡ç†ä¼˜åŒ–]
    
    B --> B1[å¼‚æ­¥ç¼–ç¨‹ä¼˜åŒ–]
    B --> B2[è¿æ¥æ± ä¼˜åŒ–]
    B --> B3[ç¼“å­˜ç­–ç•¥ä¼˜åŒ–]
    
    C --> C1[æ“ä½œç³»ç»Ÿè°ƒä¼˜]
    C --> C2[ç½‘ç»œæ ˆä¼˜åŒ–]
    C --> C3[æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–]
    
    D --> D1[CPUä¼˜åŒ–]
    D --> D2[å†…å­˜ä¼˜åŒ–]
    D --> D3[å­˜å‚¨ä¼˜åŒ–]
```

## ğŸš€ åº”ç”¨å±‚ä¼˜åŒ–

### 1. ç®—æ³•ä¸æ•°æ®ç»“æ„ä¼˜åŒ–

#### 1.1 é«˜æ•ˆæ•°æ®ç»“æ„é€‰æ‹©

```rust
// ä½¿ç”¨åˆé€‚çš„æ•°æ®ç»“æ„
use std::collections::{HashMap, BTreeMap, VecDeque, HashSet};
use ahash::{AHashMap, AHashSet}; // æ›´å¿«çš„å“ˆå¸Œå®ç°

pub struct OptimizedCache {
    // ä½¿ç”¨AHashMapæ›¿ä»£HashMapï¼Œæ€§èƒ½æå‡20-30%
    cache: AHashMap<String, CacheEntry>,
    // ä½¿ç”¨VecDequeå®ç°LRUç¼“å­˜
    access_order: VecDeque<String>,
    // ä½¿ç”¨HashSetå¿«é€ŸæŸ¥æ‰¾
    expired_keys: AHashSet<String>,
}

impl OptimizedCache {
    pub fn new(capacity: usize) -> Self {
        Self {
            cache: AHashMap::with_capacity(capacity),
            access_order: VecDeque::with_capacity(capacity),
            expired_keys: AHashSet::with_capacity(capacity / 4),
        }
    }
    
    pub fn get(&mut self, key: &str) -> Option<&CacheEntry> {
        if self.expired_keys.contains(key) {
            return None;
        }
        
        if let Some(entry) = self.cache.get(key) {
            // æ›´æ–°è®¿é—®é¡ºåº
            self.update_access_order(key);
            Some(entry)
        } else {
            None
        }
    }
    
    pub fn set(&mut self, key: String, value: CacheEntry) {
        // æ£€æŸ¥å®¹é‡é™åˆ¶
        if self.cache.len() >= self.cache.capacity() {
            self.evict_lru();
        }
        
        self.cache.insert(key.clone(), value);
        self.access_order.push_back(key);
    }
    
    fn update_access_order(&mut self, key: &str) {
        // ç§»é™¤æ—§ä½ç½®
        if let Some(pos) = self.access_order.iter().position(|k| k == key) {
            self.access_order.remove(pos);
        }
        // æ·»åŠ åˆ°æœ«å°¾
        self.access_order.push_back(key.to_string());
    }
    
    fn evict_lru(&mut self) {
        if let Some(key) = self.access_order.pop_front() {
            self.cache.remove(&key);
        }
    }
}
```

#### 1.2 é›¶æ‹·è´ä¼˜åŒ–

```rust
use bytes::{Bytes, BytesMut, BufMut};
use std::io::{self, Read};

// é›¶æ‹·è´æ•°æ®å¤„ç†
pub struct ZeroCopyProcessor {
    buffer: BytesMut,
    chunk_size: usize,
}

impl ZeroCopyProcessor {
    pub fn new(chunk_size: usize) -> Self {
        Self {
            buffer: BytesMut::with_capacity(chunk_size * 2),
            chunk_size,
        }
    }
    
    // é›¶æ‹·è´æ•°æ®è¯»å–
    pub fn process_stream<R: Read>(&mut self, mut reader: R) -> io::Result<Vec<Bytes>> {
        let mut chunks = Vec::new();
        
        loop {
            // ç¡®ä¿ç¼“å†²åŒºæœ‰è¶³å¤Ÿç©ºé—´
            if self.buffer.remaining_mut() < self.chunk_size {
                self.buffer.reserve(self.chunk_size);
            }
            
            // è¯»å–æ•°æ®åˆ°ç¼“å†²åŒº
            let bytes_read = reader.read(&mut self.buffer.chunk_mut())?;
            if bytes_read == 0 {
                break;
            }
            
            unsafe {
                self.buffer.advance_mut(bytes_read);
            }
            
            // å¤„ç†å®Œæ•´çš„æ•°æ®å—
            while self.buffer.len() >= self.chunk_size {
                let chunk = self.buffer.split_to(self.chunk_size);
                chunks.push(chunk.freeze());
            }
        }
        
        // å¤„ç†å‰©ä½™æ•°æ®
        if !self.buffer.is_empty() {
            chunks.push(self.buffer.split().freeze());
        }
        
        Ok(chunks)
    }
}

// ä½¿ç”¨ç¤ºä¾‹
pub async fn process_large_file(file_path: &str) -> Result<(), Box<dyn std::error::Error>> {
    let file = std::fs::File::open(file_path)?;
    let mut processor = ZeroCopyProcessor::new(8192);
    
    let chunks = processor.process_stream(file)?;
    
    for chunk in chunks {
        // å¤„ç†æ•°æ®å—ï¼Œæ— éœ€é¢å¤–æ‹·è´
        process_chunk(&chunk).await?;
    }
    
    Ok(())
}
```

### 2. å†…å­˜ç®¡ç†ä¼˜åŒ–

#### 2.1 å†…å­˜æ± å®ç°

```rust
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;

// å¯¹è±¡æ± å®ç°
pub struct ObjectPool<T> {
    objects: Arc<Mutex<VecDeque<T>>>,
    factory: Arc<dyn Fn() -> T + Send + Sync>,
    max_size: usize,
}

impl<T> ObjectPool<T> {
    pub fn new<F>(factory: F, max_size: usize) -> Self
    where
        F: Fn() -> T + Send + Sync + 'static,
    {
        Self {
            objects: Arc::new(Mutex::new(VecDeque::new())),
            factory: Arc::new(factory),
            max_size,
        }
    }
    
    pub fn get(&self) -> PooledObject<T> {
        let mut objects = self.objects.lock().unwrap();
        
        if let Some(obj) = objects.pop_front() {
            PooledObject::new(obj, self.objects.clone())
        } else {
            let obj = (self.factory)();
            PooledObject::new(obj, self.objects.clone())
        }
    }
    
    fn return_object(&self, obj: T) {
        let mut objects = self.objects.lock().unwrap();
        
        if objects.len() < self.max_size {
            objects.push_back(obj);
        }
        // å¦‚æœæ± å·²æ»¡ï¼Œå¯¹è±¡ä¼šè¢«ä¸¢å¼ƒ
    }
}

pub struct PooledObject<T> {
    object: Option<T>,
    pool: Arc<Mutex<VecDeque<T>>>,
}

impl<T> PooledObject<T> {
    fn new(object: T, pool: Arc<Mutex<VecDeque<T>>>) -> Self {
        Self {
            object: Some(object),
            pool,
        }
    }
    
    pub fn as_ref(&self) -> &T {
        self.object.as_ref().unwrap()
    }
    
    pub fn as_mut(&mut self) -> &mut T {
        self.object.as_mut().unwrap()
    }
}

impl<T> Drop for PooledObject<T> {
    fn drop(&mut self) {
        if let Some(obj) = self.object.take() {
            let mut objects = self.pool.lock().unwrap();
            if objects.len() < objects.capacity() {
                objects.push_back(obj);
            }
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
pub struct DatabaseConnection {
    id: u64,
    // è¿æ¥ç›¸å…³å­—æ®µ
}

impl DatabaseConnection {
    pub fn new(id: u64) -> Self {
        Self { id }
    }
    
    pub fn execute_query(&self, query: &str) -> Result<String, String> {
        // æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        Ok(format!("Result for query: {}", query))
    }
}

// è¿æ¥æ± ä½¿ç”¨
pub struct DatabaseService {
    connection_pool: ObjectPool<DatabaseConnection>,
}

impl DatabaseService {
    pub fn new() -> Self {
        let pool = ObjectPool::new(
            || DatabaseConnection::new(rand::random()),
            10, // æœ€å¤§è¿æ¥æ•°
        );
        
        Self {
            connection_pool: pool,
        }
    }
    
    pub async fn execute_query(&self, query: &str) -> Result<String, String> {
        let mut connection = self.connection_pool.get();
        connection.as_mut().execute_query(query)
    }
}
```

#### 2.2 å†…å­˜é¢„åˆ†é…ç­–ç•¥

```rust
use std::alloc::{GlobalAlloc, Layout, System};
use std::sync::atomic::{AtomicUsize, Ordering};

// è‡ªå®šä¹‰å†…å­˜åˆ†é…å™¨
pub struct MicroserviceAllocator {
    allocated: AtomicUsize,
    peak_allocated: AtomicUsize,
}

unsafe impl GlobalAlloc for MicroserviceAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let size = layout.size();
        let current = self.allocated.fetch_add(size, Ordering::Relaxed);
        
        // æ›´æ–°å³°å€¼
        let peak = self.peak_allocated.load(Ordering::Relaxed);
        if current + size > peak {
            self.peak_allocated.store(current + size, Ordering::Relaxed);
        }
        
        System.alloc(layout)
    }
    
    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        let size = layout.size();
        self.allocated.fetch_sub(size, Ordering::Relaxed);
        System.dealloc(ptr, layout);
    }
}

#[global_allocator]
static ALLOCATOR: MicroserviceAllocator = MicroserviceAllocator {
    allocated: AtomicUsize::new(0),
    peak_allocated: AtomicUsize::new(0),
};

// å†…å­˜ä½¿ç”¨ç›‘æ§
pub struct MemoryMonitor {
    allocated: AtomicUsize,
    peak_allocated: AtomicUsize,
}

impl MemoryMonitor {
    pub fn new() -> Self {
        Self {
            allocated: AtomicUsize::new(0),
            peak_allocated: AtomicUsize::new(0),
        }
    }
    
    pub fn get_current_usage(&self) -> usize {
        self.allocated.load(Ordering::Relaxed)
    }
    
    pub fn get_peak_usage(&self) -> usize {
        self.peak_allocated.load(Ordering::Relaxed)
    }
    
    pub fn record_allocation(&self, size: usize) {
        let current = self.allocated.fetch_add(size, Ordering::Relaxed);
        let peak = self.peak_allocated.load(Ordering::Relaxed);
        
        if current + size > peak {
            self.peak_allocated.store(current + size, Ordering::Relaxed);
        }
    }
    
    pub fn record_deallocation(&self, size: usize) {
        self.allocated.fetch_sub(size, Ordering::Relaxed);
    }
}
```

## âš¡ å¹¶å‘ä¼˜åŒ–

### 1. å¼‚æ­¥ç¼–ç¨‹ä¼˜åŒ–

#### 1.1 ä»»åŠ¡è°ƒåº¦ä¼˜åŒ–

```rust
use tokio::runtime::{Runtime, Builder};
use tokio::task::JoinSet;
use std::sync::Arc;

// ä¼˜åŒ–çš„è¿è¡Œæ—¶é…ç½®
pub struct OptimizedRuntime {
    runtime: Runtime,
    task_set: JoinSet<()>,
}

impl OptimizedRuntime {
    pub fn new() -> Result<Self, Box<dyn std::error::Error>> {
        let runtime = Builder::new_multi_thread()
            .worker_threads(num_cpus::get())
            .max_blocking_threads(100)
            .thread_name("microservice-worker")
            .thread_stack_size(3 * 1024 * 1024) // 3MBæ ˆå¤§å°
            .enable_all()
            .build()?;
        
        Ok(Self {
            runtime,
            task_set: JoinSet::new(),
        })
    }
    
    pub fn spawn_optimized_task<F>(&mut self, task: F)
    where
        F: Future<Output = ()> + Send + 'static,
    {
        self.task_set.spawn(task);
    }
    
    pub async fn run_until_complete(&mut self) {
        while let Some(_) = self.task_set.join_next().await {
            // ä»»åŠ¡å®Œæˆå¤„ç†
        }
    }
}

// å·¥ä½œçªƒå–è°ƒåº¦å™¨
pub struct WorkStealingScheduler {
    queues: Vec<Arc<Mutex<VecDeque<Task>>>>,
    current_queue: AtomicUsize,
}

impl WorkStealingScheduler {
    pub fn new(num_workers: usize) -> Self {
        let queues = (0..num_workers)
            .map(|_| Arc::new(Mutex::new(VecDeque::new())))
            .collect();
        
        Self {
            queues,
            current_queue: AtomicUsize::new(0),
        }
    }
    
    pub fn push_task(&self, task: Task) {
        let queue_id = self.current_queue.fetch_add(1, Ordering::Relaxed) % self.queues.len();
        let queue = &self.queues[queue_id];
        
        if let Ok(mut queue) = queue.lock() {
            queue.push_back(task);
        }
    }
    
    pub fn pop_task(&self, worker_id: usize) -> Option<Task> {
        // é¦–å…ˆå°è¯•ä»è‡ªå·±çš„é˜Ÿåˆ—è·å–ä»»åŠ¡
        if let Ok(mut queue) = self.queues[worker_id].lock() {
            if let Some(task) = queue.pop_front() {
                return Some(task);
            }
        }
        
        // å·¥ä½œçªƒå–ï¼šä»å…¶ä»–é˜Ÿåˆ—è·å–ä»»åŠ¡
        for i in 0..self.queues.len() {
            if i != worker_id {
                if let Ok(mut queue) = self.queues[i].lock() {
                    if let Some(task) = queue.pop_back() {
                        return Some(task);
                    }
                }
            }
        }
        
        None
    }
}
```

#### 1.2 é”ä¼˜åŒ–

```rust
use std::sync::{Arc, Mutex, RwLock};
use tokio::sync::{Mutex as AsyncMutex, RwLock as AsyncRwLock, Semaphore};
use std::sync::atomic::{AtomicUsize, Ordering};

// è¯»å†™é”ä¼˜åŒ–
pub struct OptimizedDataStore {
    // ä½¿ç”¨åˆ†ç‰‡é”å‡å°‘é”ç«äº‰
    shards: Vec<Arc<AsyncRwLock<HashMap<String, String>>>>,
    shard_count: usize,
}

impl OptimizedDataStore {
    pub fn new(shard_count: usize) -> Self {
        let shards = (0..shard_count)
            .map(|_| Arc::new(AsyncRwLock::new(HashMap::new())))
            .collect();
        
        Self {
            shards,
            shard_count,
        }
    }
    
    fn get_shard(&self, key: &str) -> &Arc<AsyncRwLock<HashMap<String, String>>> {
        let hash = self.hash_key(key);
        &self.shards[hash % self.shard_count]
    }
    
    fn hash_key(&self, key: &str) -> usize {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish() as usize
    }
    
    pub async fn get(&self, key: &str) -> Option<String> {
        let shard = self.get_shard(key);
        let data = shard.read().await;
        data.get(key).cloned()
    }
    
    pub async fn set(&self, key: String, value: String) {
        let shard = self.get_shard(&key);
        let mut data = shard.write().await;
        data.insert(key, value);
    }
}

// æ— é”æ•°æ®ç»“æ„
pub struct LockFreeCounter {
    counters: Vec<AtomicUsize>,
    shard_count: usize,
}

impl LockFreeCounter {
    pub fn new(shard_count: usize) -> Self {
        let counters = (0..shard_count)
            .map(|_| AtomicUsize::new(0))
            .collect();
        
        Self {
            counters,
            shard_count,
        }
    }
    
    pub fn increment(&self, thread_id: usize) {
        let shard_id = thread_id % self.shard_count;
        self.counters[shard_id].fetch_add(1, Ordering::Relaxed);
    }
    
    pub fn get_total(&self) -> usize {
        self.counters.iter()
            .map(|c| c.load(Ordering::Relaxed))
            .sum()
    }
}
```

### 2. è¿æ¥æ± ä¼˜åŒ–

#### 2.1 æ•°æ®åº“è¿æ¥æ± 

```rust
use deadpool_postgres::{Config, Pool, Runtime};
use std::time::Duration;

// ä¼˜åŒ–çš„æ•°æ®åº“è¿æ¥æ± é…ç½®
pub struct OptimizedDatabasePool {
    pool: Pool,
    metrics: ConnectionMetrics,
}

pub struct ConnectionMetrics {
    active_connections: AtomicUsize,
    total_connections: AtomicUsize,
    connection_errors: AtomicUsize,
}

impl OptimizedDatabasePool {
    pub async fn new(database_url: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let mut config = Config::new();
        config.url = Some(database_url.to_string());
        
        // è¿æ¥æ± ä¼˜åŒ–é…ç½®
        config.pool = Some(deadpool_postgres::PoolConfig {
            max_size: 20, // æœ€å¤§è¿æ¥æ•°
            min_idle: Some(5), // æœ€å°ç©ºé—²è¿æ¥æ•°
            max_lifetime: Some(Duration::from_secs(1800)), // 30åˆ†é’Ÿ
            idle_timeout: Some(Duration::from_secs(600)), // 10åˆ†é’Ÿ
            create_timeout: Some(Duration::from_secs(30)), // åˆ›å»ºè¶…æ—¶
            recycle_timeout: Some(Duration::from_secs(30)), // å›æ”¶è¶…æ—¶
        });
        
        let pool = config.create_pool(Some(Runtime::Tokio1), tokio_postgres::NoTls)?;
        
        Ok(Self {
            pool,
            metrics: ConnectionMetrics {
                active_connections: AtomicUsize::new(0),
                total_connections: AtomicUsize::new(0),
                connection_errors: AtomicUsize::new(0),
            },
        })
    }
    
    pub async fn execute_query(&self, query: &str) -> Result<Vec<Row>, Box<dyn std::error::Error>> {
        let start_time = std::time::Instant::now();
        
        let client = self.pool.get().await.map_err(|e| {
            self.metrics.connection_errors.fetch_add(1, Ordering::Relaxed);
            e
        })?;
        
        self.metrics.active_connections.fetch_add(1, Ordering::Relaxed);
        
        let result = client.query(query, &[]).await.map_err(|e| {
            self.metrics.connection_errors.fetch_add(1, Ordering::Relaxed);
            e
        })?;
        
        self.metrics.active_connections.fetch_sub(1, Ordering::Relaxed);
        
        let duration = start_time.elapsed();
        if duration > Duration::from_millis(100) {
            tracing::warn!("Slow query detected: {}ms", duration.as_millis());
        }
        
        Ok(result)
    }
    
    pub fn get_metrics(&self) -> &ConnectionMetrics {
        &self.metrics
    }
}
```

#### 2.2 HTTPè¿æ¥æ± 

```rust
use reqwest::Client;
use std::time::Duration;

// ä¼˜åŒ–çš„HTTPå®¢æˆ·ç«¯é…ç½®
pub struct OptimizedHttpClient {
    client: Client,
    metrics: HttpMetrics,
}

pub struct HttpMetrics {
    total_requests: AtomicUsize,
    successful_requests: AtomicUsize,
    failed_requests: AtomicUsize,
    total_duration: AtomicUsize, // å¾®ç§’
}

impl OptimizedHttpClient {
    pub fn new() -> Result<Self, Box<dyn std::error::Error>> {
        let client = Client::builder()
            .timeout(Duration::from_secs(30))
            .connect_timeout(Duration::from_secs(10))
            .pool_max_idle_per_host(10)
            .pool_idle_timeout(Duration::from_secs(90))
            .http2_prior_knowledge()
            .build()?;
        
        Ok(Self {
            client,
            metrics: HttpMetrics {
                total_requests: AtomicUsize::new(0),
                successful_requests: AtomicUsize::new(0),
                failed_requests: AtomicUsize::new(0),
                total_duration: AtomicUsize::new(0),
            },
        })
    }
    
    pub async fn get(&self, url: &str) -> Result<String, Box<dyn std::error::Error>> {
        let start_time = std::time::Instant::now();
        self.metrics.total_requests.fetch_add(1, Ordering::Relaxed);
        
        let response = self.client.get(url).send().await?;
        
        let duration = start_time.elapsed();
        self.metrics.total_duration.fetch_add(
            duration.as_micros() as usize,
            Ordering::Relaxed,
        );
        
        if response.status().is_success() {
            self.metrics.successful_requests.fetch_add(1, Ordering::Relaxed);
            Ok(response.text().await?)
        } else {
            self.metrics.failed_requests.fetch_add(1, Ordering::Relaxed);
            Err(format!("HTTP error: {}", response.status()).into())
        }
    }
    
    pub fn get_metrics(&self) -> &HttpMetrics {
        &self.metrics
    }
}
```

## ğŸŒ ç½‘ç»œä¼˜åŒ–

### 1. åè®®ä¼˜åŒ–

#### 1.1 HTTP/2ä¼˜åŒ–

```rust
use hyper::server::conn::Http;
use hyper::service::service_fn;
use hyper::{Body, Request, Response, StatusCode};
use tokio::net::TcpListener;

// HTTP/2æœåŠ¡å™¨ä¼˜åŒ–
pub struct OptimizedHttp2Server {
    listener: TcpListener,
    max_concurrent_streams: u32,
    initial_window_size: u32,
}

impl OptimizedHttp2Server {
    pub async fn new(addr: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let listener = TcpListener::bind(addr).await?;
        
        Ok(Self {
            listener,
            max_concurrent_streams: 1000,
            initial_window_size: 1024 * 1024, // 1MB
        })
    }
    
    pub async fn run(&self) -> Result<(), Box<dyn std::error::Error>> {
        loop {
            let (stream, _) = self.listener.accept().await?;
            
            let http = Http::new();
            let http = http
                .http2_only(true)
                .http2_max_concurrent_streams(self.max_concurrent_streams)
                .http2_initial_stream_window_size(self.initial_window_size)
                .http2_initial_connection_window_size(self.initial_window_size * 2);
            
            tokio::spawn(async move {
                if let Err(e) = http.serve_connection(stream, service_fn(handle_request)).await {
                    eprintln!("HTTP/2 connection error: {}", e);
                }
            });
        }
    }
}

async fn handle_request(req: Request<Body>) -> Result<Response<Body>, hyper::Error> {
    // å¤„ç†è¯·æ±‚
    Ok(Response::new(Body::from("Hello, HTTP/2!")))
}
```

#### 1.2 gRPCä¼˜åŒ–

```rust
use tonic::transport::Server;
use tonic::Request;

// gRPCæœåŠ¡å™¨ä¼˜åŒ–é…ç½®
pub struct OptimizedGrpcServer {
    max_concurrent_streams: u32,
    max_frame_size: u32,
    keep_alive_interval: Duration,
    keep_alive_timeout: Duration,
}

impl OptimizedGrpcServer {
    pub fn new() -> Self {
        Self {
            max_concurrent_streams: 1000,
            max_frame_size: 4 * 1024 * 1024, // 4MB
            keep_alive_interval: Duration::from_secs(30),
            keep_alive_timeout: Duration::from_secs(5),
        }
    }
    
    pub async fn serve<T>(&self, service: T, addr: &str) -> Result<(), Box<dyn std::error::Error>>
    where
        T: tonic::transport::server::NamedService + Clone + Send + Sync + 'static,
    {
        let server = Server::builder()
            .http2_keepalive_interval(Some(self.keep_alive_interval))
            .http2_keepalive_timeout(Some(self.keep_alive_timeout))
            .http2_keepalive_while_idle(true)
            .concurrency_limit_per_connection(self.max_concurrent_streams)
            .max_frame_size(self.max_frame_size)
            .add_service(service);
        
        server.serve(addr.parse()?).await?;
        Ok(())
    }
}
```

### 2. è´Ÿè½½å‡è¡¡ä¼˜åŒ–

#### 2.1 æ™ºèƒ½è´Ÿè½½å‡è¡¡

```rust
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::time::{Duration, Instant};

// æœåŠ¡å™¨èŠ‚ç‚¹ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct ServerNode {
    pub id: String,
    pub address: String,
    pub weight: u32,
    pub current_connections: AtomicUsize,
    pub response_time: AtomicUsize, // å¾®ç§’
    pub last_health_check: AtomicUsize, // æ—¶é—´æˆ³
}

// è´Ÿè½½å‡è¡¡å™¨
pub struct LoadBalancer {
    nodes: Vec<Arc<ServerNode>>,
    current_index: AtomicUsize,
    health_check_interval: Duration,
}

impl LoadBalancer {
    pub fn new(nodes: Vec<ServerNode>) -> Self {
        Self {
            nodes: nodes.into_iter().map(Arc::new).collect(),
            current_index: AtomicUsize::new(0),
            health_check_interval: Duration::from_secs(30),
        }
    }
    
    // åŠ æƒè½®è¯¢ç®—æ³•
    pub fn get_next_node(&self) -> Option<Arc<ServerNode>> {
        if self.nodes.is_empty() {
            return None;
        }
        
        let mut best_node = None;
        let mut best_score = 0.0;
        
        for node in &self.nodes {
            let connections = node.current_connections.load(Ordering::Relaxed) as f64;
            let response_time = node.response_time.load(Ordering::Relaxed) as f64;
            let weight = node.weight as f64;
            
            // è®¡ç®—èŠ‚ç‚¹å¾—åˆ†ï¼ˆæƒé‡ / (è¿æ¥æ•° + å“åº”æ—¶é—´å› å­)ï¼‰
            let score = weight / (connections + 1.0 + response_time / 1000.0);
            
            if score > best_score {
                best_score = score;
                best_node = Some(node.clone());
            }
        }
        
        best_node
    }
    
    // æœ€å°‘è¿æ¥ç®—æ³•
    pub fn get_least_connections_node(&self) -> Option<Arc<ServerNode>> {
        self.nodes.iter()
            .min_by_key(|node| node.current_connections.load(Ordering::Relaxed))
            .cloned()
    }
    
    // å“åº”æ—¶é—´æœ€çŸ­ç®—æ³•
    pub fn get_fastest_node(&self) -> Option<Arc<ServerNode>> {
        self.nodes.iter()
            .min_by_key(|node| node.response_time.load(Ordering::Relaxed))
            .cloned()
    }
    
    // å¥åº·æ£€æŸ¥
    pub async fn health_check(&self) {
        for node in &self.nodes {
            let start_time = Instant::now();
            
            // æ‰§è¡Œå¥åº·æ£€æŸ¥
            let is_healthy = self.check_node_health(&node.address).await;
            
            let response_time = start_time.elapsed().as_micros() as usize;
            node.response_time.store(response_time, Ordering::Relaxed);
            node.last_health_check.store(
                start_time.elapsed().as_secs() as usize,
                Ordering::Relaxed,
            );
            
            if !is_healthy {
                tracing::warn!("Node {} is unhealthy", node.id);
            }
        }
    }
    
    async fn check_node_health(&self, address: &str) -> bool {
        // å®ç°å¥åº·æ£€æŸ¥é€»è¾‘
        // è¿™é‡Œå¯ä»¥å‘é€HTTPè¯·æ±‚æˆ–gRPCè°ƒç”¨
        true
    }
}
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### 1. æŒ‡æ ‡æ”¶é›†

```rust
use prometheus::{Counter, Histogram, Gauge, Registry};

// æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
pub struct PerformanceMetrics {
    // è¯·æ±‚æŒ‡æ ‡
    pub request_total: Counter,
    pub request_duration: Histogram,
    pub request_size: Histogram,
    pub response_size: Histogram,
    
    // ç³»ç»ŸæŒ‡æ ‡
    pub memory_usage: Gauge,
    pub cpu_usage: Gauge,
    pub active_connections: Gauge,
    
    // ä¸šåŠ¡æŒ‡æ ‡
    pub cache_hits: Counter,
    pub cache_misses: Counter,
    pub database_queries: Counter,
    pub database_query_duration: Histogram,
}

impl PerformanceMetrics {
    pub fn new(registry: &Registry) -> Result<Self, prometheus::Error> {
        let request_total = Counter::new(
            "http_requests_total",
            "Total number of HTTP requests"
        )?;
        
        let request_duration = Histogram::new(
            "http_request_duration_seconds",
            "HTTP request duration in seconds"
        )?;
        
        let request_size = Histogram::new(
            "http_request_size_bytes",
            "HTTP request size in bytes"
        )?;
        
        let response_size = Histogram::new(
            "http_response_size_bytes",
            "HTTP response size in bytes"
        )?;
        
        let memory_usage = Gauge::new(
            "memory_usage_bytes",
            "Current memory usage in bytes"
        )?;
        
        let cpu_usage = Gauge::new(
            "cpu_usage_percent",
            "Current CPU usage percentage"
        )?;
        
        let active_connections = Gauge::new(
            "active_connections",
            "Number of active connections"
        )?;
        
        let cache_hits = Counter::new(
            "cache_hits_total",
            "Total number of cache hits"
        )?;
        
        let cache_misses = Counter::new(
            "cache_misses_total",
            "Total number of cache misses"
        )?;
        
        let database_queries = Counter::new(
            "database_queries_total",
            "Total number of database queries"
        )?;
        
        let database_query_duration = Histogram::new(
            "database_query_duration_seconds",
            "Database query duration in seconds"
        )?;
        
        // æ³¨å†ŒæŒ‡æ ‡
        registry.register(Box::new(request_total.clone()))?;
        registry.register(Box::new(request_duration.clone()))?;
        registry.register(Box::new(request_size.clone()))?;
        registry.register(Box::new(response_size.clone()))?;
        registry.register(Box::new(memory_usage.clone()))?;
        registry.register(Box::new(cpu_usage.clone()))?;
        registry.register(Box::new(active_connections.clone()))?;
        registry.register(Box::new(cache_hits.clone()))?;
        registry.register(Box::new(cache_misses.clone()))?;
        registry.register(Box::new(database_queries.clone()))?;
        registry.register(Box::new(database_query_duration.clone()))?;
        
        Ok(Self {
            request_total,
            request_duration,
            request_size,
            response_size,
            memory_usage,
            cpu_usage,
            active_connections,
            cache_hits,
            cache_misses,
            database_queries,
            database_query_duration,
        })
    }
}
```

### 2. æ€§èƒ½åˆ†æå·¥å…·

```rust
use std::time::{Duration, Instant};
use std::sync::Arc;
use tokio::sync::Mutex;

// æ€§èƒ½åˆ†æå™¨
pub struct PerformanceProfiler {
    samples: Arc<Mutex<Vec<PerformanceSample>>>,
    max_samples: usize,
}

#[derive(Debug, Clone)]
pub struct PerformanceSample {
    pub timestamp: Instant,
    pub operation: String,
    pub duration: Duration,
    pub memory_usage: usize,
    pub cpu_usage: f64,
}

impl PerformanceProfiler {
    pub fn new(max_samples: usize) -> Self {
        Self {
            samples: Arc::new(Mutex::new(Vec::with_capacity(max_samples))),
            max_samples,
        }
    }
    
    pub async fn record_sample(&self, sample: PerformanceSample) {
        let mut samples = self.samples.lock().await;
        
        if samples.len() >= self.max_samples {
            samples.remove(0);
        }
        
        samples.push(sample);
    }
    
    pub async fn get_statistics(&self) -> PerformanceStatistics {
        let samples = self.samples.lock().await;
        
        if samples.is_empty() {
            return PerformanceStatistics::default();
        }
        
        let mut total_duration = Duration::ZERO;
        let mut min_duration = Duration::MAX;
        let mut max_duration = Duration::ZERO;
        let mut total_memory = 0;
        let mut total_cpu = 0.0;
        
        for sample in samples.iter() {
            total_duration += sample.duration;
            min_duration = min_duration.min(sample.duration);
            max_duration = max_duration.max(sample.duration);
            total_memory += sample.memory_usage;
            total_cpu += sample.cpu_usage;
        }
        
        let count = samples.len();
        
        PerformanceStatistics {
            sample_count: count,
            average_duration: total_duration / count as u32,
            min_duration,
            max_duration,
            average_memory_usage: total_memory / count,
            average_cpu_usage: total_cpu / count as f64,
        }
    }
}

#[derive(Debug, Default)]
pub struct PerformanceStatistics {
    pub sample_count: usize,
    pub average_duration: Duration,
    pub min_duration: Duration,
    pub max_duration: Duration,
    pub average_memory_usage: usize,
    pub average_cpu_usage: f64,
}
```

## ğŸ”§ éƒ¨ç½²ä¼˜åŒ–

### 1. å®¹å™¨ä¼˜åŒ–

```dockerfile
# ä¼˜åŒ–çš„Dockerfile
FROM rust:1.90-slim as builder

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶Cargoæ–‡ä»¶
COPY Cargo.toml Cargo.lock ./

# æ„å»ºä¾èµ–ï¼ˆåˆ©ç”¨Dockerç¼“å­˜ï¼‰
RUN cargo build --release --locked

# å¤åˆ¶æºä»£ç 
COPY src ./src

# é‡æ–°æ„å»ºï¼ˆåªç¼–è¯‘æºä»£ç å˜æ›´ï¼‰
RUN touch src/main.rs && cargo build --release --locked

# è¿è¡Œé˜¶æ®µ
FROM debian:bookworm-slim

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /app/target/release/microservice-server /app/

# è®¾ç½®æƒé™
RUN chown -R appuser:appuser /app
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¯åŠ¨å‘½ä»¤
CMD ["./microservice-server"]
```

### 2. ç³»ç»Ÿè°ƒä¼˜

```bash
#!/bin/bash
# ç³»ç»Ÿæ€§èƒ½è°ƒä¼˜è„šæœ¬

echo "ğŸ”§ å¼€å§‹ç³»ç»Ÿæ€§èƒ½è°ƒä¼˜..."

# 1. ç½‘ç»œå‚æ•°ä¼˜åŒ–
echo "ä¼˜åŒ–ç½‘ç»œå‚æ•°..."
echo 'net.core.rmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_rmem = 4096 65536 134217728' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_wmem = 4096 65536 134217728' >> /etc/sysctl.conf
echo 'net.core.netdev_max_backlog = 5000' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_congestion_control = bbr' >> /etc/sysctl.conf

# 2. æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
echo "ä¼˜åŒ–æ–‡ä»¶æè¿°ç¬¦é™åˆ¶..."
echo '* soft nofile 65536' >> /etc/security/limits.conf
echo '* hard nofile 65536' >> /etc/security/limits.conf

# 3. å†…å­˜ç®¡ç†ä¼˜åŒ–
echo "ä¼˜åŒ–å†…å­˜ç®¡ç†..."
echo 'vm.swappiness = 10' >> /etc/sysctl.conf
echo 'vm.dirty_ratio = 15' >> /etc/sysctl.conf
echo 'vm.dirty_background_ratio = 5' >> /etc/sysctl.conf

# 4. åº”ç”¨sysctlé…ç½®
sysctl -p

echo "âœ… ç³»ç»Ÿæ€§èƒ½è°ƒä¼˜å®Œæˆ"
```

## ğŸ“š æœ€ä½³å®è·µæ€»ç»“

### 1. æ€§èƒ½ä¼˜åŒ–åŸåˆ™

- **æµ‹é‡ä¼˜å…ˆ**: å…ˆæµ‹é‡å†ä¼˜åŒ–ï¼Œé¿å…è¿‡æ—©ä¼˜åŒ–
- **åˆ†å±‚ä¼˜åŒ–**: ä»åº”ç”¨å±‚åˆ°ç³»ç»Ÿå±‚é€å±‚ä¼˜åŒ–
- **æŒç»­ç›‘æ§**: å»ºç«‹å®Œå–„çš„æ€§èƒ½ç›‘æ§ä½“ç³»
- **æ¸è¿›æ”¹è¿›**: å°æ­¥å¿«è·‘ï¼ŒæŒç»­æ”¹è¿›

### 2. å…³é”®ä¼˜åŒ–ç‚¹

- **å†…å­˜ç®¡ç†**: åˆç†ä½¿ç”¨å†…å­˜æ± å’Œå¯¹è±¡æ± 
- **å¹¶å‘æ§åˆ¶**: ä¼˜åŒ–é”çš„ä½¿ç”¨å’Œå¼‚æ­¥ç¼–ç¨‹
- **ç½‘ç»œä¼˜åŒ–**: ä½¿ç”¨HTTP/2å’Œè¿æ¥æ± 
- **ç¼“å­˜ç­–ç•¥**: å®ç°å¤šçº§ç¼“å­˜å’Œæ™ºèƒ½å¤±æ•ˆ

### 3. ç›‘æ§æŒ‡æ ‡

- **å“åº”æ—¶é—´**: P50ã€P95ã€P99å»¶è¿Ÿ
- **ååé‡**: RPSå’Œå¹¶å‘è¿æ¥æ•°
- **èµ„æºä½¿ç”¨**: CPUã€å†…å­˜ã€ç½‘ç»œä½¿ç”¨ç‡
- **é”™è¯¯ç‡**: 4xxå’Œ5xxé”™è¯¯æ¯”ä¾‹

### 4. ä¼˜åŒ–å·¥å…·

- **æ€§èƒ½åˆ†æ**: ä½¿ç”¨profilingå·¥å…·åˆ†æçƒ­ç‚¹
- **å†…å­˜åˆ†æ**: ä½¿ç”¨å†…å­˜åˆ†æå·¥å…·æ£€æµ‹æ³„æ¼
- **ç½‘ç»œåˆ†æ**: ä½¿ç”¨ç½‘ç»œåˆ†æå·¥å…·ä¼˜åŒ–ä¼ è¾“
- **ç³»ç»Ÿç›‘æ§**: ä½¿ç”¨ç³»ç»Ÿç›‘æ§å·¥å…·è·Ÿè¸ªèµ„æº

## ğŸ”— ç›¸å…³èµ„æº

- [Rustæ€§èƒ½ä¼˜åŒ–æŒ‡å—](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html)
- [Tokioæ€§èƒ½è°ƒä¼˜](https://tokio.rs/tokio/tutorial)
- [Prometheusç›‘æ§](https://prometheus.io/docs/)
- [å¤šæ¡†æ¶é›†æˆæœ€ä½³å®è·µ](./å¤šæ¡†æ¶é›†æˆæœ€ä½³å®è·µ.md)

---

**æ³¨æ„**: æœ¬æ–‡æ¡£åŸºäº2025å¹´9æœˆçš„æœ€æ–°æŠ€æœ¯æ ˆï¼Œå»ºè®®å®šæœŸæ›´æ–°ä»¥ä¿æŒæ—¶æ•ˆæ€§ã€‚

