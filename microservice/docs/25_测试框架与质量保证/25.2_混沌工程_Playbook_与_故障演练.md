# 混沌工程 Playbook 与故障演练

> 基于Rust 1.90和2025年最新技术栈的混沌工程完整实践指南

## 📋 概述

本文档提供了混沌工程的完整实践指南，包括故障注入场景、演练流程、监控指标和恢复策略，帮助团队建立可靠的微服务系统。

## 🎯 混沌工程目标

### 1. 核心目标

- ✅ **提升系统韧性**：通过故障注入发现系统弱点
- ✅ **验证恢复能力**：确保故障恢复机制有效
- ✅ **建立信心**：团队对系统可靠性有信心
- ✅ **持续改进**：基于演练结果持续优化系统

### 2. 成功指标

| 指标 | 目标值 | 测量方法 |
|------|--------|----------|
| 故障检测时间 | < 1分钟 | 监控告警 |
| 故障恢复时间 | < 5分钟 | 自动化恢复 |
| 数据丢失率 | 0% | 数据一致性检查 |
| 服务可用性 | > 99.9% | 监控系统 |
| 团队响应时间 | < 2分钟 | 演练记录 |

## 🔧 故障注入场景库

### 1. 基础设施故障

#### 1.1 网络故障

```yaml
# chaos-mesh/network-chaos.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay
  namespace: microservice
spec:
  action: delay
  mode: one
  selector:
    namespaces:
      - microservice
    labelSelectors:
      app: microservice
  delay:
    latency: 100ms
    correlation: 100
    jitter: 10ms
  duration: 300s
```

#### 1.2 节点故障

```yaml
# chaos-mesh/node-chaos.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NodeChaos
metadata:
  name: node-failure
  namespace: microservice
spec:
  action: node-failure
  mode: one
  selector:
    namespaces:
      - microservice
  duration: 60s
```

#### 1.3 磁盘故障

```yaml
# chaos-mesh/io-chaos.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: IOChaos
metadata:
  name: disk-latency
  namespace: microservice
spec:
  action: latency
  mode: one
  selector:
    namespaces:
      - microservice
  volumePath: /var/lib/data
  path: /var/lib/data/test
  delay: 100ms
  percent: 50
  duration: 300s
```

### 2. 应用层故障

#### 2.1 服务故障

```rust
// chaos-engineering/service-chaos.rs
use std::time::Duration;
use tokio::time::sleep;
use rand::Rng;

pub struct ServiceChaos {
    failure_rate: f64,
    latency_range: (u64, u64),
    error_types: Vec<String>,
}

impl ServiceChaos {
    pub fn new(failure_rate: f64, latency_range: (u64, u64)) -> Self {
        Self {
            failure_rate,
            latency_range,
            error_types: vec![
                "timeout".to_string(),
                "connection_refused".to_string(),
                "internal_error".to_string(),
            ],
        }
    }
    
    pub async fn inject_failure(&self) -> Result<(), Box<dyn std::error::Error>> {
        let mut rng = rand::thread_rng();
        
        // 随机延迟
        let delay = rng.gen_range(self.latency_range.0..=self.latency_range.1);
        sleep(Duration::from_millis(delay)).await;
        
        // 随机故障
        if rng.gen::<f64>() < self.failure_rate {
            let error_type = &self.error_types[rng.gen_range(0..self.error_types.len())];
            return Err(format!("Chaos injection: {}", error_type).into());
        }
        
        Ok(())
    }
}

// 在服务中使用
pub async fn handle_request(&self, request: Request) -> Result<Response, Error> {
    // 注入故障
    self.chaos.inject_failure().await?;
    
    // 正常业务逻辑
    self.process_request(request).await
}
```

#### 2.2 数据库故障

```rust
// chaos-engineering/database-chaos.rs
use sqlx::{PgPool, Error as SqlxError};
use std::time::Duration;
use tokio::time::sleep;

pub struct DatabaseChaos {
    pool: PgPool,
    failure_rate: f64,
    timeout_duration: Duration,
}

impl DatabaseChaos {
    pub fn new(pool: PgPool, failure_rate: f64) -> Self {
        Self {
            pool,
            failure_rate,
            timeout_duration: Duration::from_secs(30),
        }
    }
    
    pub async fn inject_connection_failure(&self) -> Result<(), SqlxError> {
        let mut rng = rand::thread_rng();
        
        if rng.gen::<f64>() < self.failure_rate {
            // 模拟连接超时
            sleep(self.timeout_duration).await;
            return Err(SqlxError::PoolTimedOut);
        }
        
        Ok(())
    }
    
    pub async fn inject_query_failure(&self) -> Result<(), SqlxError> {
        let mut rng = rand::thread_rng();
        
        if rng.gen::<f64>() < self.failure_rate {
            // 模拟查询失败
            return Err(SqlxError::RowNotFound);
        }
        
        Ok(())
    }
}
```

### 3. 依赖服务故障

#### 3.1 外部API故障

```rust
// chaos-engineering/external-api-chaos.rs
use reqwest::Client;
use std::time::Duration;
use tokio::time::timeout;

pub struct ExternalApiChaos {
    client: Client,
    failure_rate: f64,
    timeout_duration: Duration,
}

impl ExternalApiChaos {
    pub async fn call_external_api(&self, url: &str) -> Result<String, Box<dyn std::error::Error>> {
        let mut rng = rand::thread_rng();
        
        // 随机故障注入
        if rng.gen::<f64>() < self.failure_rate {
            // 模拟超时
            timeout(self.timeout_duration, async {
                sleep(Duration::from_secs(60)).await;
                Ok("timeout".to_string())
            }).await??;
        }
        
        // 正常API调用
        let response = self.client.get(url).send().await?;
        let body = response.text().await?;
        Ok(body)
    }
}
```

## 📊 监控与告警

### 1. 关键指标监控

```rust
// monitoring/chaos-metrics.rs
use prometheus::{Counter, Histogram, Gauge, Registry};
use std::sync::Arc;

pub struct ChaosMetrics {
    pub chaos_injections_total: Counter,
    pub chaos_duration_seconds: Histogram,
    pub service_availability: Gauge,
    pub error_rate: Gauge,
    pub recovery_time_seconds: Histogram,
}

impl ChaosMetrics {
    pub fn new(registry: &Registry) -> Self {
        let chaos_injections_total = Counter::new(
            "chaos_injections_total",
            "Total number of chaos injections"
        ).unwrap();
        
        let chaos_duration_seconds = Histogram::new(
            "chaos_duration_seconds",
            "Duration of chaos injections"
        ).unwrap();
        
        let service_availability = Gauge::new(
            "service_availability",
            "Service availability percentage"
        ).unwrap();
        
        let error_rate = Gauge::new(
            "error_rate",
            "Error rate percentage"
        ).unwrap();
        
        let recovery_time_seconds = Histogram::new(
            "recovery_time_seconds",
            "Time to recover from failures"
        ).unwrap();
        
        registry.register(Box::new(chaos_injections_total.clone())).unwrap();
        registry.register(Box::new(chaos_duration_seconds.clone())).unwrap();
        registry.register(Box::new(service_availability.clone())).unwrap();
        registry.register(Box::new(error_rate.clone())).unwrap();
        registry.register(Box::new(recovery_time_seconds.clone())).unwrap();
        
        Self {
            chaos_injections_total,
            chaos_duration_seconds,
            service_availability,
            error_rate,
            recovery_time_seconds,
        }
    }
}
```

### 2. 告警规则

```yaml
# prometheus/chaos-alerts.yml
groups:
  - name: chaos-engineering
    rules:
      - alert: HighErrorRateDuringChaos
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected during chaos injection"
          
      - alert: ServiceUnavailable
        expr: up{job="microservice"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service is unavailable"
          
      - alert: LongRecoveryTime
        expr: histogram_quantile(0.95, recovery_time_seconds) > 300
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Recovery time is too long"
          
      - alert: DataInconsistency
        expr: data_consistency_check_failures_total > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Data inconsistency detected"
```

## 🚀 演练流程

### 1. 演练前准备

```bash
#!/bin/bash
# scripts/chaos-engineering-prep.sh

echo "🔧 准备混沌工程演练..."

# 1. 检查系统状态
echo "检查系统状态..."
kubectl get pods -n microservice
kubectl get services -n microservice

# 2. 备份重要数据
echo "备份重要数据..."
kubectl exec -n microservice deployment/postgres -- pg_dump -U postgres microservice > backup_$(date +%Y%m%d_%H%M%S).sql

# 3. 检查监控系统
echo "检查监控系统..."
curl -f http://prometheus:9090/api/v1/query?query=up
curl -f http://grafana:3000/api/health

# 4. 通知团队
echo "通知团队..."
curl -X POST -H 'Content-type: application/json' \
  --data '{"text":"混沌工程演练即将开始，请做好准备"}' \
  $SLACK_WEBHOOK_URL

echo "✅ 演练准备完成"
```

### 2. 演练执行

```bash
#!/bin/bash
# scripts/chaos-engineering-execute.sh

set -e

echo "🎯 开始混沌工程演练..."

# 1. 网络延迟注入
echo "注入网络延迟..."
kubectl apply -f chaos-mesh/network-chaos.yaml

# 等待并监控
sleep 60
echo "监控网络延迟影响..."
kubectl get networkchaos -n microservice

# 2. 服务故障注入
echo "注入服务故障..."
kubectl apply -f chaos-mesh/pod-chaos.yaml

# 等待并监控
sleep 60
echo "监控服务故障影响..."
kubectl get podchaos -n microservice

# 3. 数据库故障注入
echo "注入数据库故障..."
kubectl apply -f chaos-mesh/io-chaos.yaml

# 等待并监控
sleep 60
echo "监控数据库故障影响..."
kubectl get iochaos -n microservice

# 4. 清理故障注入
echo "清理故障注入..."
kubectl delete -f chaos-mesh/network-chaos.yaml
kubectl delete -f chaos-mesh/pod-chaos.yaml
kubectl delete -f chaos-mesh/io-chaos.yaml

echo "✅ 演练执行完成"
```

### 3. 演练后分析

```bash
#!/bin/bash
# scripts/chaos-engineering-analysis.sh

echo "📊 分析演练结果..."

# 1. 收集指标数据
echo "收集指标数据..."
curl -s "http://prometheus:9090/api/v1/query_range?query=rate(http_requests_total[5m])&start=$(date -d '1 hour ago' +%s)&end=$(date +%s)&step=60" > metrics_data.json

# 2. 生成报告
echo "生成演练报告..."
python3 scripts/generate_chaos_report.py metrics_data.json

# 3. 检查数据一致性
echo "检查数据一致性..."
kubectl exec -n microservice deployment/postgres -- psql -U postgres -d microservice -c "SELECT COUNT(*) FROM orders;"

# 4. 发送报告
echo "发送演练报告..."
curl -X POST -H 'Content-type: application/json' \
  --data @chaos_report.json \
  $SLACK_WEBHOOK_URL

echo "✅ 演练分析完成"
```

## 🔄 自动化演练

### 1. 定时演练

```yaml
# k8s/chaos-engineering-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: chaos-engineering-cronjob
  namespace: microservice
spec:
  schedule: "0 2 * * 1"  # 每周一凌晨2点执行
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: chaos-engineering
            image: chaos-engineering:latest
            command:
            - /bin/bash
            - -c
            - |
              echo "开始定时混沌工程演练..."
              ./scripts/chaos-engineering-prep.sh
              ./scripts/chaos-engineering-execute.sh
              ./scripts/chaos-engineering-analysis.sh
              echo "定时演练完成"
            env:
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: slack-webhook
                  key: url
          restartPolicy: OnFailure
```

### 2. 持续集成集成

```yaml
# .github/workflows/chaos-engineering.yml
name: Chaos Engineering

on:
  schedule:
    - cron: '0 2 * * 1'  # 每周一凌晨2点
  workflow_dispatch:

jobs:
  chaos-engineering:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      - name: Setup Chaos Mesh
        run: |
          curl -sSL https://mirrors.chaos-mesh.org/v2.6.0/install.sh | bash
      
      - name: Run Chaos Engineering
        run: |
          ./scripts/chaos-engineering-prep.sh
          ./scripts/chaos-engineering-execute.sh
          ./scripts/chaos-engineering-analysis.sh
      
      - name: Upload Results
        uses: actions/upload-artifact@v3
        with:
          name: chaos-engineering-results
          path: chaos_report.json
```

## 📚 最佳实践

### 1. 演练设计原则

- ✅ **渐进式演练**：从简单到复杂，逐步增加难度
- ✅ **业务时间**：在业务低峰期进行演练
- ✅ **团队参与**：确保相关团队参与演练
- ✅ **文档记录**：详细记录演练过程和结果

### 2. 故障注入原则

- ✅ **可控性**：确保故障注入可以控制和停止
- ✅ **可观测性**：充分监控故障注入的影响
- ✅ **可恢复性**：确保系统可以快速恢复
- ✅ **可重复性**：演练结果可以重复验证

### 3. 团队协作

- ✅ **明确角色**：明确每个团队成员的角色和职责
- ✅ **沟通机制**：建立有效的沟通机制
- ✅ **应急预案**：制定详细的应急预案
- ✅ **持续改进**：基于演练结果持续改进

## 🔗 相关文档

- [微服务测试策略与混沌工程](./25.1_微服务测试策略与混沌工程.md)
- [错误处理与容错机制](./12_最佳实践与案例研究/12.2_错误处理与容错机制.md)
- [监控与告警系统](./24_高级监控与告警/24.1_分布式追踪与告警系统.md)
- [性能基准测试](./11_性能优化与测试/11.1_性能基准测试.md)

## 📝 更新日志

- **2025-01-XX**: 初始版本创建
- **2025-01-XX**: 添加Rust 1.90最新实践
- **2025-01-XX**: 完善故障注入场景
- **2025-01-XX**: 增加自动化演练流程

---

**注意**：本文档基于Rust 1.90和2025年最新技术栈，建议定期更新以保持时效性。
